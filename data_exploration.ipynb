{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# Import resampling modules from imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question\n",
    "\n",
    "1. What should be the minimum duration of we want to classify?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trajectories_df = load_filtered_data(years=('2019',), folder='../AIS_data', min_data_points=100)\n",
    "\n",
    "# def sort_row(row):\n",
    "#     # load into arrays\n",
    "#     e  = np.asarray(row['elapsed_s'])\n",
    "#     la = np.asarray(row['LAT'])\n",
    "#     lo = np.asarray(row['LON'])\n",
    "#     # get the sort‐order\n",
    "#     idx = np.argsort(e)\n",
    "#     # return a Series so apply(...) will build a DataFrame with matching columns\n",
    "#     return pd.Series({\n",
    "#         'elapsed_s': e[idx],\n",
    "#         'LAT'      : la[idx],\n",
    "#         'LON'      : lo[idx]\n",
    "#     })\n",
    "\n",
    "# # apply and overwrite in one go\n",
    "# trajectories_df[['elapsed_s','LAT','LON']] = trajectories_df.apply(sort_row, axis=1)\n",
    "\n",
    "trajectories_df = pd.read_pickle('../AIS_preprocessed_data/trajectories_2019.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MMSI</th>\n",
       "      <th>elapsed_s</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>VesselType</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>367659930</td>\n",
       "      <td>[0, 69, 138, 210, 279, 349, 420, 488, 570, 639...</td>\n",
       "      <td>[30.4289, 30.42774, 30.42675, 30.42573, 30.424...</td>\n",
       "      <td>[-87.99302, -87.99258, -87.9919, -87.99129, -8...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>367553360</td>\n",
       "      <td>[0, 70, 149, 220, 301, 379, 449, 559, 630, 709...</td>\n",
       "      <td>[29.01648, 29.01666, 29.01664, 29.01661, 29.01...</td>\n",
       "      <td>[-91.83069, -91.83175, -91.83304, -91.83416, -...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>367461560</td>\n",
       "      <td>[0, 64, 134, 204, 274, 354, 425, 495, 45847, 4...</td>\n",
       "      <td>[29.36644, 29.36952, 29.37291, 29.3762, 29.379...</td>\n",
       "      <td>[-91.38801, -91.38525, -91.38225, -91.37948, -...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>538007067</td>\n",
       "      <td>[0, 120, 301, 483, 662, 843, 1023, 1204, 1383,...</td>\n",
       "      <td>[28.82299, 28.82325, 28.8236, 28.82388, 28.824...</td>\n",
       "      <td>[-89.33299, -89.33357, -89.3343, -89.33491, -8...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>369053000</td>\n",
       "      <td>[0, 70, 139, 209, 270, 340, 410, 473, 540, 610...</td>\n",
       "      <td>[30.18058, 30.17847, 30.17641, 30.17425, 30.17...</td>\n",
       "      <td>[-88.56405, -88.56745, -88.57083, -88.57432, -...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296782</th>\n",
       "      <td>538006166</td>\n",
       "      <td>[0, 81, 224, 301, 401, 510, 581, 651, 750, 831...</td>\n",
       "      <td>[28.91509, 28.91185, 28.90624, 28.90286, 28.89...</td>\n",
       "      <td>[-89.42226, -89.42518, -89.43059, -89.43154, -...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296783</th>\n",
       "      <td>538005865</td>\n",
       "      <td>[0, 69, 130, 337, 440, 620, 681, 811, 891, 104...</td>\n",
       "      <td>[28.91911, 28.91597, 28.91333, 28.90537, 28.90...</td>\n",
       "      <td>[-89.4197, -89.422, -89.4239, -89.43129, -89.4...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296784</th>\n",
       "      <td>369293000</td>\n",
       "      <td>[0, 100, 230, 309, 391, 480, 741, 811, 879, 90...</td>\n",
       "      <td>[29.07654, 29.07338, 29.06873, 29.06566, 29.06...</td>\n",
       "      <td>[-90.22863, -90.22913, -90.22987, -90.23059, -...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296785</th>\n",
       "      <td>636017526</td>\n",
       "      <td>[0, 90, 161, 240, 307, 433, 498, 565, 636, 715...</td>\n",
       "      <td>[30.64235, 30.63707, 30.63251, 30.6274, 30.622...</td>\n",
       "      <td>[-88.03225, -88.03235, -88.03236, -88.03249, -...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296786</th>\n",
       "      <td>538004384</td>\n",
       "      <td>[0, 70, 250, 317, 380, 417, 480, 560, 631, 701...</td>\n",
       "      <td>[28.91971, 28.91616, 28.90798, 28.90495, 28.90...</td>\n",
       "      <td>[-89.41942, -89.42204, -89.42903, -89.43138, -...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>296787 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             MMSI                                          elapsed_s  \\\n",
       "0       367659930  [0, 69, 138, 210, 279, 349, 420, 488, 570, 639...   \n",
       "1       367553360  [0, 70, 149, 220, 301, 379, 449, 559, 630, 709...   \n",
       "2       367461560  [0, 64, 134, 204, 274, 354, 425, 495, 45847, 4...   \n",
       "3       538007067  [0, 120, 301, 483, 662, 843, 1023, 1204, 1383,...   \n",
       "4       369053000  [0, 70, 139, 209, 270, 340, 410, 473, 540, 610...   \n",
       "...           ...                                                ...   \n",
       "296782  538006166  [0, 81, 224, 301, 401, 510, 581, 651, 750, 831...   \n",
       "296783  538005865  [0, 69, 130, 337, 440, 620, 681, 811, 891, 104...   \n",
       "296784  369293000  [0, 100, 230, 309, 391, 480, 741, 811, 879, 90...   \n",
       "296785  636017526  [0, 90, 161, 240, 307, 433, 498, 565, 636, 715...   \n",
       "296786  538004384  [0, 70, 250, 317, 380, 417, 480, 560, 631, 701...   \n",
       "\n",
       "                                                      LAT  \\\n",
       "0       [30.4289, 30.42774, 30.42675, 30.42573, 30.424...   \n",
       "1       [29.01648, 29.01666, 29.01664, 29.01661, 29.01...   \n",
       "2       [29.36644, 29.36952, 29.37291, 29.3762, 29.379...   \n",
       "3       [28.82299, 28.82325, 28.8236, 28.82388, 28.824...   \n",
       "4       [30.18058, 30.17847, 30.17641, 30.17425, 30.17...   \n",
       "...                                                   ...   \n",
       "296782  [28.91509, 28.91185, 28.90624, 28.90286, 28.89...   \n",
       "296783  [28.91911, 28.91597, 28.91333, 28.90537, 28.90...   \n",
       "296784  [29.07654, 29.07338, 29.06873, 29.06566, 29.06...   \n",
       "296785  [30.64235, 30.63707, 30.63251, 30.6274, 30.622...   \n",
       "296786  [28.91971, 28.91616, 28.90798, 28.90495, 28.90...   \n",
       "\n",
       "                                                      LON  VesselType  Label  \n",
       "0       [-87.99302, -87.99258, -87.9919, -87.99129, -8...        31.0      0  \n",
       "1       [-91.83069, -91.83175, -91.83304, -91.83416, -...        30.0      0  \n",
       "2       [-91.38801, -91.38525, -91.38225, -91.37948, -...        90.0      0  \n",
       "3       [-89.33299, -89.33357, -89.3343, -89.33491, -8...        70.0      0  \n",
       "4       [-88.56405, -88.56745, -88.57083, -88.57432, -...        90.0      0  \n",
       "...                                                   ...         ...    ...  \n",
       "296782  [-89.42226, -89.42518, -89.43059, -89.43154, -...        80.0      0  \n",
       "296783  [-89.4197, -89.422, -89.4239, -89.43129, -89.4...        80.0      0  \n",
       "296784  [-90.22863, -90.22913, -90.22987, -90.23059, -...        90.0      0  \n",
       "296785  [-88.03225, -88.03235, -88.03236, -88.03249, -...        70.0      0  \n",
       "296786  [-89.41942, -89.42204, -89.42903, -89.43138, -...        70.0      0  \n",
       "\n",
       "[296787 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectories_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(296787, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectories_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MMSI', 'elapsed_s', 'LAT', 'LON', 'VesselType', 'Label'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectories_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "0    295090\n",
      "1      1697\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "counts = trajectories_df['Label'].value_counts()\n",
    "print(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Flatten all sample intervals from all trajectories\n",
    "all_intervals = []\n",
    "\n",
    "for elapsed in trajectories_df['elapsed_s']:\n",
    "    elapsed = np.array(elapsed)\n",
    "    if len(elapsed) > 1:\n",
    "        # intervals = np.diff(np.sort(elapsed))  # ensure time is sorted\n",
    "        intervals = np.diff(elapsed)\n",
    "        valid_intervals = intervals[(intervals <= 1000)]  # filter\n",
    "        all_intervals.extend(valid_intervals)\n",
    "        # all_intervals.extend(intervals)\n",
    "all_intervals = np.array(all_intervals)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.hist(all_intervals, bins=100, edgecolor='black')\n",
    "plt.title(\"Histogram of Sample Intervals\")\n",
    "plt.xlabel(\"Interval Duration (seconds)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(301706, 6)\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# # threshold in seconds\n",
    "# THRESHOLD = 3600\n",
    "\n",
    "# def split_row_into_segments(row, threshold=THRESHOLD):\n",
    "#     \"\"\"\n",
    "#     Given a row with list‐columns ['elapsed_s','LAT','LON'],\n",
    "#     split into multiple segments whenever elapsed_s gaps > threshold.\n",
    "#     Returns a list of dicts, each dict is one sub-trajectory.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     e  = row['elapsed_s']\n",
    "#     la = row['LAT']\n",
    "#     lo = row['LON']\n",
    "    \n",
    "\n",
    "#     # compute gaps and find break points\n",
    "#     gaps = np.diff(e)\n",
    "#     # break *after* any index i where gap[i] > threshold\n",
    "#     break_idxs = np.where(gaps > threshold)[0]\n",
    "\n",
    "#     # define segment boundaries: starts at 0, each break+1, ends at len(e)\n",
    "#     boundaries = np.concatenate([[0], break_idxs + 1, [len(e)]])\n",
    "\n",
    "#     segments = []\n",
    "\n",
    "#     e = np.asarray(e)\n",
    "#     for start, end in zip(boundaries[:-1], boundaries[1:]):\n",
    "#         seg = {\n",
    "#             'MMSI':        row['MMSI'],\n",
    "#             'VesselType':  row['VesselType'],\n",
    "#             'Label':       row['Label'],\n",
    "#             'elapsed_s':   e[start:end]-e[start],  # normalize to start at 0\n",
    "#             'LAT':         la[start:end],\n",
    "#             'LON':         lo[start:end],\n",
    "#         }\n",
    "#         # only keep segments with at least two points\n",
    "#         if len(seg['elapsed_s']) > 100:\n",
    "#             segments.append(seg)\n",
    "#     return segments\n",
    "\n",
    "# # apply to all rows and flatten\n",
    "# all_segments = []\n",
    "# for _, row in trajectories_df.iterrows():\n",
    "#     all_segments.extend(split_row_into_segments(row))\n",
    "\n",
    "# # build new DataFrame\n",
    "# segmented_df = pd.DataFrame(all_segments)\n",
    "\n",
    "# # reset index if you like\n",
    "# segmented_df = segmented_df.reset_index(drop=True)\n",
    "# segmented_df.to_pickle('../AIS_preprocessed_data/segmented_trajectories_2019.pkl')\n",
    "\n",
    "# Load the segmented DataFrame\n",
    "segmented_df = pd.read_pickle('../AIS_preprocessed_data/segmented_trajectories_2019.pkl')\n",
    "print(segmented_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    295090\n",
       "1      1697\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectories_df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    300108\n",
       "1      1598\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmented_df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MMSI</th>\n",
       "      <th>VesselType</th>\n",
       "      <th>Label</th>\n",
       "      <th>elapsed_s</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>367659930</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 69, 138, 210, 279, 349, 420, 488, 570, 639...</td>\n",
       "      <td>[30.4289, 30.42774, 30.42675, 30.42573, 30.424...</td>\n",
       "      <td>[-87.99302, -87.99258, -87.9919, -87.99129, -8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>367553360</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 70, 149, 220, 301, 379, 449, 559, 630, 709...</td>\n",
       "      <td>[29.01648, 29.01666, 29.01664, 29.01661, 29.01...</td>\n",
       "      <td>[-91.83069, -91.83175, -91.83304, -91.83416, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>367461560</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 65, 131, 197, 263, 335, 402, 467, 533, 600...</td>\n",
       "      <td>[29.38964, 29.38584, 29.38206, 29.37743, 29.37...</td>\n",
       "      <td>[-91.36791, -91.37142, -91.37496, -91.37891, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>538007067</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 120, 301, 483, 662, 843, 1023, 1204, 1383,...</td>\n",
       "      <td>[28.82299, 28.82325, 28.8236, 28.82388, 28.824...</td>\n",
       "      <td>[-89.33299, -89.33357, -89.3343, -89.33491, -8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>369053000</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 70, 139, 209, 270, 340, 410, 473, 540, 610...</td>\n",
       "      <td>[30.18058, 30.17847, 30.17641, 30.17425, 30.17...</td>\n",
       "      <td>[-88.56405, -88.56745, -88.57083, -88.57432, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301701</th>\n",
       "      <td>538006166</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 81, 224, 301, 401, 510, 581, 651, 750, 831...</td>\n",
       "      <td>[28.91509, 28.91185, 28.90624, 28.90286, 28.89...</td>\n",
       "      <td>[-89.42226, -89.42518, -89.43059, -89.43154, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301702</th>\n",
       "      <td>538005865</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 69, 130, 337, 440, 620, 681, 811, 891, 104...</td>\n",
       "      <td>[28.91911, 28.91597, 28.91333, 28.90537, 28.90...</td>\n",
       "      <td>[-89.4197, -89.422, -89.4239, -89.43129, -89.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301703</th>\n",
       "      <td>369293000</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 100, 230, 309, 391, 480, 741, 811, 879, 90...</td>\n",
       "      <td>[29.07654, 29.07338, 29.06873, 29.06566, 29.06...</td>\n",
       "      <td>[-90.22863, -90.22913, -90.22987, -90.23059, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301704</th>\n",
       "      <td>636017526</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 90, 161, 240, 307, 433, 498, 565, 636, 715...</td>\n",
       "      <td>[30.64235, 30.63707, 30.63251, 30.6274, 30.622...</td>\n",
       "      <td>[-88.03225, -88.03235, -88.03236, -88.03249, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301705</th>\n",
       "      <td>538004384</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 70, 250, 317, 380, 417, 480, 560, 631, 701...</td>\n",
       "      <td>[28.91971, 28.91616, 28.90798, 28.90495, 28.90...</td>\n",
       "      <td>[-89.41942, -89.42204, -89.42903, -89.43138, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>301706 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             MMSI  VesselType  Label  \\\n",
       "0       367659930        31.0      0   \n",
       "1       367553360        30.0      0   \n",
       "2       367461560        90.0      0   \n",
       "3       538007067        70.0      0   \n",
       "4       369053000        90.0      0   \n",
       "...           ...         ...    ...   \n",
       "301701  538006166        80.0      0   \n",
       "301702  538005865        80.0      0   \n",
       "301703  369293000        90.0      0   \n",
       "301704  636017526        70.0      0   \n",
       "301705  538004384        70.0      0   \n",
       "\n",
       "                                                elapsed_s  \\\n",
       "0       [0, 69, 138, 210, 279, 349, 420, 488, 570, 639...   \n",
       "1       [0, 70, 149, 220, 301, 379, 449, 559, 630, 709...   \n",
       "2       [0, 65, 131, 197, 263, 335, 402, 467, 533, 600...   \n",
       "3       [0, 120, 301, 483, 662, 843, 1023, 1204, 1383,...   \n",
       "4       [0, 70, 139, 209, 270, 340, 410, 473, 540, 610...   \n",
       "...                                                   ...   \n",
       "301701  [0, 81, 224, 301, 401, 510, 581, 651, 750, 831...   \n",
       "301702  [0, 69, 130, 337, 440, 620, 681, 811, 891, 104...   \n",
       "301703  [0, 100, 230, 309, 391, 480, 741, 811, 879, 90...   \n",
       "301704  [0, 90, 161, 240, 307, 433, 498, 565, 636, 715...   \n",
       "301705  [0, 70, 250, 317, 380, 417, 480, 560, 631, 701...   \n",
       "\n",
       "                                                      LAT  \\\n",
       "0       [30.4289, 30.42774, 30.42675, 30.42573, 30.424...   \n",
       "1       [29.01648, 29.01666, 29.01664, 29.01661, 29.01...   \n",
       "2       [29.38964, 29.38584, 29.38206, 29.37743, 29.37...   \n",
       "3       [28.82299, 28.82325, 28.8236, 28.82388, 28.824...   \n",
       "4       [30.18058, 30.17847, 30.17641, 30.17425, 30.17...   \n",
       "...                                                   ...   \n",
       "301701  [28.91509, 28.91185, 28.90624, 28.90286, 28.89...   \n",
       "301702  [28.91911, 28.91597, 28.91333, 28.90537, 28.90...   \n",
       "301703  [29.07654, 29.07338, 29.06873, 29.06566, 29.06...   \n",
       "301704  [30.64235, 30.63707, 30.63251, 30.6274, 30.622...   \n",
       "301705  [28.91971, 28.91616, 28.90798, 28.90495, 28.90...   \n",
       "\n",
       "                                                      LON  \n",
       "0       [-87.99302, -87.99258, -87.9919, -87.99129, -8...  \n",
       "1       [-91.83069, -91.83175, -91.83304, -91.83416, -...  \n",
       "2       [-91.36791, -91.37142, -91.37496, -91.37891, -...  \n",
       "3       [-89.33299, -89.33357, -89.3343, -89.33491, -8...  \n",
       "4       [-88.56405, -88.56745, -88.57083, -88.57432, -...  \n",
       "...                                                   ...  \n",
       "301701  [-89.42226, -89.42518, -89.43059, -89.43154, -...  \n",
       "301702  [-89.4197, -89.422, -89.4239, -89.43129, -89.4...  \n",
       "301703  [-90.22863, -90.22913, -90.22987, -90.23059, -...  \n",
       "301704  [-88.03225, -88.03235, -88.03236, -88.03249, -...  \n",
       "301705  [-89.41942, -89.42204, -89.42903, -89.43138, -...  \n",
       "\n",
       "[301706 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmented_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forrest with handcrafted classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from scipy.stats import mode\n",
    "\n",
    "# # Fast haversine distance (vectorized) in meters\n",
    "# def haversine_np(lat1, lon1, lat2, lon2):\n",
    "#     R = 6371000  # Radius of Earth in meters\n",
    "#     lat1 = np.radians(lat1)\n",
    "#     lon1 = np.radians(lon1)\n",
    "#     lat2 = np.radians(lat2)\n",
    "#     lon2 = np.radians(lon2)\n",
    "    \n",
    "#     dlat = lat2 - lat1\n",
    "#     dlon = lon2 - lon1\n",
    "    \n",
    "#     a = np.sin(dlat / 2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0)**2\n",
    "#     c = 2 * np.arcsin(np.sqrt(a))\n",
    "#     return R * c\n",
    "\n",
    "# def extract_features(row):\n",
    "#     elapsed = np.array(row['elapsed_s'])\n",
    "#     lat = np.array(row['LAT'])\n",
    "#     lon = np.array(row['LON'])\n",
    "\n",
    "#     # Vectorized distance computation\n",
    "#     distances = haversine_np(lat[:-1], lon[:-1], lat[1:], lon[1:])  # shape: (n-1,)\n",
    "    \n",
    "#     dt = np.diff(elapsed) + 1e-10 # shape: (n-1,)\n",
    "#     speed = distances / dt  # shape: (n-1,)\n",
    "#     acceleration = np.diff(speed) / dt[1:]  # shape: (n-2,)\n",
    "\n",
    "#     def extract_stats(arr):\n",
    "#         return [\n",
    "#             np.mean(arr),\n",
    "#             np.max(arr),\n",
    "#             np.min(arr),\n",
    "#             np.std(arr),\n",
    "#             mode(arr, keepdims=False).mode,\n",
    "#             np.percentile(arr, 25),\n",
    "#             np.percentile(arr, 50),\n",
    "#             np.percentile(arr, 75)\n",
    "#         ]\n",
    "\n",
    "#     stat_names = ['mean', 'max', 'min', 'std', 'mode', 'q1', 'q2', 'q3']\n",
    "#     feature_names = []\n",
    "#     for prefix in ['speed', 'distance', 'acceleration', 'time_gap','lat', 'lon']:\n",
    "#         feature_names.extend([f\"{prefix}_{s}\" for s in stat_names])\n",
    "\n",
    "#     feature_values = (\n",
    "#         extract_stats(speed)\n",
    "#         + extract_stats(distances)\n",
    "#         + extract_stats(acceleration)\n",
    "#         + extract_stats(dt)\n",
    "#         + extract_stats(lat)\n",
    "#         + extract_stats(lon)\n",
    "#     )\n",
    "\n",
    "#     return pd.DataFrame([feature_values], columns=feature_names)\n",
    "# # Apply feature extraction to each row\n",
    "# features_df = pd.concat(segmented_df.apply(extract_features, axis=1).tolist(), ignore_index=True)\n",
    "\n",
    "\n",
    "# features_df.to_pickle('../AIS_preprocessed_data/features_trajectories_2019.pkl')\n",
    "# Load the features DataFrame\n",
    "features_df = pd.read_pickle('../AIS_preprocessed_data/features_trajectories_2019.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df['Label'] = segmented_df['Label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.to_csv('../AIS_preprocessed_data/features_trajectories_2019.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speed_mean</th>\n",
       "      <th>speed_max</th>\n",
       "      <th>speed_min</th>\n",
       "      <th>speed_std</th>\n",
       "      <th>speed_mode</th>\n",
       "      <th>speed_q1</th>\n",
       "      <th>speed_q2</th>\n",
       "      <th>speed_q3</th>\n",
       "      <th>distance_mean</th>\n",
       "      <th>distance_max</th>\n",
       "      <th>...</th>\n",
       "      <th>lat_q3</th>\n",
       "      <th>lon_mean</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_std</th>\n",
       "      <th>lon_mode</th>\n",
       "      <th>lon_q1</th>\n",
       "      <th>lon_q2</th>\n",
       "      <th>lon_q3</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.849572</td>\n",
       "      <td>2.044116</td>\n",
       "      <td>1.495934</td>\n",
       "      <td>0.090731</td>\n",
       "      <td>1.839331</td>\n",
       "      <td>1.795889</td>\n",
       "      <td>1.856550</td>\n",
       "      <td>1.911966</td>\n",
       "      <td>135.071257</td>\n",
       "      <td>264.140849</td>\n",
       "      <td>...</td>\n",
       "      <td>30.362690</td>\n",
       "      <td>-87.903259</td>\n",
       "      <td>-87.76132</td>\n",
       "      <td>-87.99302</td>\n",
       "      <td>0.068003</td>\n",
       "      <td>-87.99302</td>\n",
       "      <td>-87.960960</td>\n",
       "      <td>-87.922550</td>\n",
       "      <td>-87.848695</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.243128</td>\n",
       "      <td>4.468756</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.325308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030436</td>\n",
       "      <td>1.227719</td>\n",
       "      <td>1.544401</td>\n",
       "      <td>145.142859</td>\n",
       "      <td>2841.874087</td>\n",
       "      <td>...</td>\n",
       "      <td>29.020655</td>\n",
       "      <td>-91.502626</td>\n",
       "      <td>-91.23235</td>\n",
       "      <td>-91.85809</td>\n",
       "      <td>0.224377</td>\n",
       "      <td>-91.32419</td>\n",
       "      <td>-91.768765</td>\n",
       "      <td>-91.328140</td>\n",
       "      <td>-91.324105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.754980</td>\n",
       "      <td>10.152139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.110417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024849</td>\n",
       "      <td>0.244928</td>\n",
       "      <td>1.120400</td>\n",
       "      <td>120.601385</td>\n",
       "      <td>2065.622075</td>\n",
       "      <td>...</td>\n",
       "      <td>29.247860</td>\n",
       "      <td>-91.404438</td>\n",
       "      <td>-91.36791</td>\n",
       "      <td>-91.47050</td>\n",
       "      <td>0.028035</td>\n",
       "      <td>-91.39651</td>\n",
       "      <td>-91.410160</td>\n",
       "      <td>-91.396490</td>\n",
       "      <td>-91.387170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.054933</td>\n",
       "      <td>0.528916</td>\n",
       "      <td>0.004212</td>\n",
       "      <td>0.048892</td>\n",
       "      <td>0.024173</td>\n",
       "      <td>0.026561</td>\n",
       "      <td>0.045788</td>\n",
       "      <td>0.065964</td>\n",
       "      <td>10.568758</td>\n",
       "      <td>81.068426</td>\n",
       "      <td>...</td>\n",
       "      <td>28.822770</td>\n",
       "      <td>-89.333770</td>\n",
       "      <td>-89.33024</td>\n",
       "      <td>-89.33521</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>-89.33479</td>\n",
       "      <td>-89.334740</td>\n",
       "      <td>-89.334340</td>\n",
       "      <td>-89.333300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.108983</td>\n",
       "      <td>7.442290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.851432</td>\n",
       "      <td>0.015885</td>\n",
       "      <td>0.255487</td>\n",
       "      <td>2.427915</td>\n",
       "      <td>6.065710</td>\n",
       "      <td>216.861544</td>\n",
       "      <td>2717.328784</td>\n",
       "      <td>...</td>\n",
       "      <td>30.180550</td>\n",
       "      <td>-88.744727</td>\n",
       "      <td>-88.54420</td>\n",
       "      <td>-88.88934</td>\n",
       "      <td>0.131171</td>\n",
       "      <td>-88.88031</td>\n",
       "      <td>-88.879640</td>\n",
       "      <td>-88.776920</td>\n",
       "      <td>-88.601815</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301701</th>\n",
       "      <td>6.299446</td>\n",
       "      <td>6.930492</td>\n",
       "      <td>4.685812</td>\n",
       "      <td>0.522108</td>\n",
       "      <td>4.685812</td>\n",
       "      <td>5.944622</td>\n",
       "      <td>6.576137</td>\n",
       "      <td>6.680766</td>\n",
       "      <td>681.770504</td>\n",
       "      <td>2844.183786</td>\n",
       "      <td>...</td>\n",
       "      <td>28.798198</td>\n",
       "      <td>-89.308369</td>\n",
       "      <td>-89.08625</td>\n",
       "      <td>-89.43154</td>\n",
       "      <td>0.104131</td>\n",
       "      <td>-89.43154</td>\n",
       "      <td>-89.416560</td>\n",
       "      <td>-89.323005</td>\n",
       "      <td>-89.211875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301702</th>\n",
       "      <td>6.189746</td>\n",
       "      <td>6.821701</td>\n",
       "      <td>3.443472</td>\n",
       "      <td>0.644929</td>\n",
       "      <td>3.443472</td>\n",
       "      <td>6.044247</td>\n",
       "      <td>6.441361</td>\n",
       "      <td>6.587360</td>\n",
       "      <td>574.446311</td>\n",
       "      <td>1785.005854</td>\n",
       "      <td>...</td>\n",
       "      <td>28.790492</td>\n",
       "      <td>-89.325142</td>\n",
       "      <td>-89.16524</td>\n",
       "      <td>-89.43129</td>\n",
       "      <td>0.079961</td>\n",
       "      <td>-89.42653</td>\n",
       "      <td>-89.414905</td>\n",
       "      <td>-89.320230</td>\n",
       "      <td>-89.266795</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301703</th>\n",
       "      <td>5.137518</td>\n",
       "      <td>5.654067</td>\n",
       "      <td>3.547199</td>\n",
       "      <td>0.304828</td>\n",
       "      <td>3.547199</td>\n",
       "      <td>4.949292</td>\n",
       "      <td>5.138249</td>\n",
       "      <td>5.344579</td>\n",
       "      <td>537.621115</td>\n",
       "      <td>1376.406977</td>\n",
       "      <td>...</td>\n",
       "      <td>28.964675</td>\n",
       "      <td>-90.096276</td>\n",
       "      <td>-89.84271</td>\n",
       "      <td>-90.23363</td>\n",
       "      <td>0.116995</td>\n",
       "      <td>-90.23363</td>\n",
       "      <td>-90.207423</td>\n",
       "      <td>-90.126710</td>\n",
       "      <td>-90.001112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301704</th>\n",
       "      <td>7.070819</td>\n",
       "      <td>8.183824</td>\n",
       "      <td>5.002604</td>\n",
       "      <td>0.481781</td>\n",
       "      <td>5.002604</td>\n",
       "      <td>6.905803</td>\n",
       "      <td>7.075561</td>\n",
       "      <td>7.343370</td>\n",
       "      <td>665.507580</td>\n",
       "      <td>2086.436941</td>\n",
       "      <td>...</td>\n",
       "      <td>30.479425</td>\n",
       "      <td>-88.062989</td>\n",
       "      <td>-88.01349</td>\n",
       "      <td>-88.25952</td>\n",
       "      <td>0.060417</td>\n",
       "      <td>-88.03209</td>\n",
       "      <td>-88.077433</td>\n",
       "      <td>-88.032710</td>\n",
       "      <td>-88.024760</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301705</th>\n",
       "      <td>6.347115</td>\n",
       "      <td>7.236027</td>\n",
       "      <td>4.581902</td>\n",
       "      <td>0.774160</td>\n",
       "      <td>4.581902</td>\n",
       "      <td>5.489919</td>\n",
       "      <td>6.789326</td>\n",
       "      <td>6.918124</td>\n",
       "      <td>667.499729</td>\n",
       "      <td>2691.125046</td>\n",
       "      <td>...</td>\n",
       "      <td>28.813140</td>\n",
       "      <td>-89.321703</td>\n",
       "      <td>-89.12329</td>\n",
       "      <td>-89.43168</td>\n",
       "      <td>0.094813</td>\n",
       "      <td>-89.42465</td>\n",
       "      <td>-89.420075</td>\n",
       "      <td>-89.348480</td>\n",
       "      <td>-89.232665</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>301706 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        speed_mean  speed_max  speed_min  speed_std  speed_mode  speed_q1  \\\n",
       "0         1.849572   2.044116   1.495934   0.090731    1.839331  1.795889   \n",
       "1         1.243128   4.468756   0.000000   1.325308    0.000000  0.030436   \n",
       "2         1.754980  10.152139   0.000000   3.110417    0.000000  0.024849   \n",
       "3         0.054933   0.528916   0.004212   0.048892    0.024173  0.026561   \n",
       "4         3.108983   7.442290   0.000000   2.851432    0.015885  0.255487   \n",
       "...            ...        ...        ...        ...         ...       ...   \n",
       "301701    6.299446   6.930492   4.685812   0.522108    4.685812  5.944622   \n",
       "301702    6.189746   6.821701   3.443472   0.644929    3.443472  6.044247   \n",
       "301703    5.137518   5.654067   3.547199   0.304828    3.547199  4.949292   \n",
       "301704    7.070819   8.183824   5.002604   0.481781    5.002604  6.905803   \n",
       "301705    6.347115   7.236027   4.581902   0.774160    4.581902  5.489919   \n",
       "\n",
       "        speed_q2  speed_q3  distance_mean  distance_max  ...     lat_q3  \\\n",
       "0       1.856550  1.911966     135.071257    264.140849  ...  30.362690   \n",
       "1       1.227719  1.544401     145.142859   2841.874087  ...  29.020655   \n",
       "2       0.244928  1.120400     120.601385   2065.622075  ...  29.247860   \n",
       "3       0.045788  0.065964      10.568758     81.068426  ...  28.822770   \n",
       "4       2.427915  6.065710     216.861544   2717.328784  ...  30.180550   \n",
       "...          ...       ...            ...           ...  ...        ...   \n",
       "301701  6.576137  6.680766     681.770504   2844.183786  ...  28.798198   \n",
       "301702  6.441361  6.587360     574.446311   1785.005854  ...  28.790492   \n",
       "301703  5.138249  5.344579     537.621115   1376.406977  ...  28.964675   \n",
       "301704  7.075561  7.343370     665.507580   2086.436941  ...  30.479425   \n",
       "301705  6.789326  6.918124     667.499729   2691.125046  ...  28.813140   \n",
       "\n",
       "         lon_mean   lon_max   lon_min   lon_std  lon_mode     lon_q1  \\\n",
       "0      -87.903259 -87.76132 -87.99302  0.068003 -87.99302 -87.960960   \n",
       "1      -91.502626 -91.23235 -91.85809  0.224377 -91.32419 -91.768765   \n",
       "2      -91.404438 -91.36791 -91.47050  0.028035 -91.39651 -91.410160   \n",
       "3      -89.333770 -89.33024 -89.33521  0.001293 -89.33479 -89.334740   \n",
       "4      -88.744727 -88.54420 -88.88934  0.131171 -88.88031 -88.879640   \n",
       "...           ...       ...       ...       ...       ...        ...   \n",
       "301701 -89.308369 -89.08625 -89.43154  0.104131 -89.43154 -89.416560   \n",
       "301702 -89.325142 -89.16524 -89.43129  0.079961 -89.42653 -89.414905   \n",
       "301703 -90.096276 -89.84271 -90.23363  0.116995 -90.23363 -90.207423   \n",
       "301704 -88.062989 -88.01349 -88.25952  0.060417 -88.03209 -88.077433   \n",
       "301705 -89.321703 -89.12329 -89.43168  0.094813 -89.42465 -89.420075   \n",
       "\n",
       "           lon_q2     lon_q3  Label  \n",
       "0      -87.922550 -87.848695      0  \n",
       "1      -91.328140 -91.324105      0  \n",
       "2      -91.396490 -91.387170      0  \n",
       "3      -89.334340 -89.333300      0  \n",
       "4      -88.776920 -88.601815      0  \n",
       "...           ...        ...    ...  \n",
       "301701 -89.323005 -89.211875      0  \n",
       "301702 -89.320230 -89.266795      0  \n",
       "301703 -90.126710 -90.001112      0  \n",
       "301704 -88.032710 -88.024760      0  \n",
       "301705 -89.348480 -89.232665      0  \n",
       "\n",
       "[301706 rows x 49 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from scipy.stats import mode\n",
    "\n",
    "# # Fast haversine distance (vectorized) in meters\n",
    "# def haversine_np(lat1, lon1, lat2, lon2):\n",
    "#     R = 6371  # Radius of Earth in meters\n",
    "#     lat1 = np.radians(lat1)\n",
    "#     lon1 = np.radians(lon1)\n",
    "#     lat2 = np.radians(lat2)\n",
    "#     lon2 = np.radians(lon2)\n",
    "    \n",
    "#     dlat = lat2 - lat1\n",
    "#     dlon = lon2 - lon1\n",
    "    \n",
    "#     a = np.sin(dlat / 2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0)**2\n",
    "#     c = 2 * np.arcsin(np.sqrt(a))\n",
    "#     return R * c\n",
    "\n",
    "# def extract_features(row):\n",
    "#     elapsed = np.array(row['elapsed_s'])\n",
    "#     lat = np.array(row['LAT'])\n",
    "#     lon = np.array(row['LON'])\n",
    "\n",
    "#     # Vectorized distance computation\n",
    "#     distances = haversine_np(lat[:-1], lon[:-1], lat[1:], lon[1:])  # shape: (n-1,)\n",
    "    \n",
    "#     dt = (np.diff(elapsed) + 1e-10)/60 # shape: (n-1,)\n",
    "\n",
    "\n",
    "#     speed = distances / dt  # shape: (n-1,)\n",
    "#     acceleration = np.diff(speed) / dt[1:]  # shape: (n-2,)\n",
    "\n",
    "\n",
    "#     break_duration = 0 # G1\n",
    "#     trip_duration = elapsed[-1] - elapsed[0] # G2\n",
    "\n",
    "#     # Mask for movement (speed > 0.1 km/min)\n",
    "#     threshold = 0.1  # km/min\n",
    "#     moving_mask = speed > threshold\n",
    "\n",
    "#     # Euclidean distance and total distance while moving\n",
    "#     euclidean_dist = np.sum(distances[moving_mask])\n",
    "#     total_moving_dist = np.sum(distances[moving_mask])  # same here unless specified otherwise\n",
    "\n",
    "#     # Movement efficiency (G3)\n",
    "#     movement_efficiency = euclidean_dist / total_moving_dist if total_moving_dist > 0 else 0 # G3\n",
    "\n",
    "#     trips_per_year = 0 # G4 (placeholder, needs actual logic to count trips per year)\n",
    "\n",
    "#     # G5: Pings per Minute in Movement\n",
    "#     pings_in_movement = np.sum(moving_mask)\n",
    "#     time_in_movement = np.sum(elapsed[moving_mask])\n",
    "#     pings_per_minute = pings_in_movement / time_in_movement if time_in_movement > 0 else 0 # G5\n",
    "\n",
    "#     # What is a forward/backward trip?\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# # Apply feature extraction to each row\n",
    "# features_df = pd.concat(segmented_df.apply(extract_features, axis=1).tolist(), ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.to_csv(\"data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speed_mean</th>\n",
       "      <th>speed_max</th>\n",
       "      <th>speed_min</th>\n",
       "      <th>speed_std</th>\n",
       "      <th>speed_mode</th>\n",
       "      <th>speed_q1</th>\n",
       "      <th>speed_q2</th>\n",
       "      <th>speed_q3</th>\n",
       "      <th>distance_mean</th>\n",
       "      <th>distance_max</th>\n",
       "      <th>...</th>\n",
       "      <th>lat_q2</th>\n",
       "      <th>lat_q3</th>\n",
       "      <th>lon_mean</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_std</th>\n",
       "      <th>lon_mode</th>\n",
       "      <th>lon_q1</th>\n",
       "      <th>lon_q2</th>\n",
       "      <th>lon_q3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.849572</td>\n",
       "      <td>2.044116</td>\n",
       "      <td>1.495934</td>\n",
       "      <td>0.090731</td>\n",
       "      <td>1.839331</td>\n",
       "      <td>1.795889</td>\n",
       "      <td>1.856550</td>\n",
       "      <td>1.911966</td>\n",
       "      <td>135.071257</td>\n",
       "      <td>264.140849</td>\n",
       "      <td>...</td>\n",
       "      <td>30.301030</td>\n",
       "      <td>30.362690</td>\n",
       "      <td>-87.903259</td>\n",
       "      <td>-87.76132</td>\n",
       "      <td>-87.99302</td>\n",
       "      <td>0.068003</td>\n",
       "      <td>-87.99302</td>\n",
       "      <td>-87.960960</td>\n",
       "      <td>-87.922550</td>\n",
       "      <td>-87.848695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.243128</td>\n",
       "      <td>4.468756</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.325308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030436</td>\n",
       "      <td>1.227719</td>\n",
       "      <td>1.544401</td>\n",
       "      <td>145.142859</td>\n",
       "      <td>2841.874087</td>\n",
       "      <td>...</td>\n",
       "      <td>28.999880</td>\n",
       "      <td>29.020655</td>\n",
       "      <td>-91.502626</td>\n",
       "      <td>-91.23235</td>\n",
       "      <td>-91.85809</td>\n",
       "      <td>0.224377</td>\n",
       "      <td>-91.32419</td>\n",
       "      <td>-91.768765</td>\n",
       "      <td>-91.328140</td>\n",
       "      <td>-91.324105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.754980</td>\n",
       "      <td>10.152139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.110417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024849</td>\n",
       "      <td>0.244928</td>\n",
       "      <td>1.120400</td>\n",
       "      <td>120.601385</td>\n",
       "      <td>2065.622075</td>\n",
       "      <td>...</td>\n",
       "      <td>29.243710</td>\n",
       "      <td>29.247860</td>\n",
       "      <td>-91.404438</td>\n",
       "      <td>-91.36791</td>\n",
       "      <td>-91.47050</td>\n",
       "      <td>0.028035</td>\n",
       "      <td>-91.39651</td>\n",
       "      <td>-91.410160</td>\n",
       "      <td>-91.396490</td>\n",
       "      <td>-91.387170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.054933</td>\n",
       "      <td>0.528916</td>\n",
       "      <td>0.004212</td>\n",
       "      <td>0.048892</td>\n",
       "      <td>0.024173</td>\n",
       "      <td>0.026561</td>\n",
       "      <td>0.045788</td>\n",
       "      <td>0.065964</td>\n",
       "      <td>10.568758</td>\n",
       "      <td>81.068426</td>\n",
       "      <td>...</td>\n",
       "      <td>28.822280</td>\n",
       "      <td>28.822770</td>\n",
       "      <td>-89.333770</td>\n",
       "      <td>-89.33024</td>\n",
       "      <td>-89.33521</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>-89.33479</td>\n",
       "      <td>-89.334740</td>\n",
       "      <td>-89.334340</td>\n",
       "      <td>-89.333300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.108983</td>\n",
       "      <td>7.442290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.851432</td>\n",
       "      <td>0.015885</td>\n",
       "      <td>0.255487</td>\n",
       "      <td>2.427915</td>\n",
       "      <td>6.065710</td>\n",
       "      <td>216.861544</td>\n",
       "      <td>2717.328784</td>\n",
       "      <td>...</td>\n",
       "      <td>30.167670</td>\n",
       "      <td>30.180550</td>\n",
       "      <td>-88.744727</td>\n",
       "      <td>-88.54420</td>\n",
       "      <td>-88.88934</td>\n",
       "      <td>0.131171</td>\n",
       "      <td>-88.88031</td>\n",
       "      <td>-88.879640</td>\n",
       "      <td>-88.776920</td>\n",
       "      <td>-88.601815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301701</th>\n",
       "      <td>6.299446</td>\n",
       "      <td>6.930492</td>\n",
       "      <td>4.685812</td>\n",
       "      <td>0.522108</td>\n",
       "      <td>4.685812</td>\n",
       "      <td>5.944622</td>\n",
       "      <td>6.576137</td>\n",
       "      <td>6.680766</td>\n",
       "      <td>681.770504</td>\n",
       "      <td>2844.183786</td>\n",
       "      <td>...</td>\n",
       "      <td>28.651085</td>\n",
       "      <td>28.798198</td>\n",
       "      <td>-89.308369</td>\n",
       "      <td>-89.08625</td>\n",
       "      <td>-89.43154</td>\n",
       "      <td>0.104131</td>\n",
       "      <td>-89.43154</td>\n",
       "      <td>-89.416560</td>\n",
       "      <td>-89.323005</td>\n",
       "      <td>-89.211875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301702</th>\n",
       "      <td>6.189746</td>\n",
       "      <td>6.821701</td>\n",
       "      <td>3.443472</td>\n",
       "      <td>0.644929</td>\n",
       "      <td>3.443472</td>\n",
       "      <td>6.044247</td>\n",
       "      <td>6.441361</td>\n",
       "      <td>6.587360</td>\n",
       "      <td>574.446311</td>\n",
       "      <td>1785.005854</td>\n",
       "      <td>...</td>\n",
       "      <td>28.638040</td>\n",
       "      <td>28.790492</td>\n",
       "      <td>-89.325142</td>\n",
       "      <td>-89.16524</td>\n",
       "      <td>-89.43129</td>\n",
       "      <td>0.079961</td>\n",
       "      <td>-89.42653</td>\n",
       "      <td>-89.414905</td>\n",
       "      <td>-89.320230</td>\n",
       "      <td>-89.266795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301703</th>\n",
       "      <td>5.137518</td>\n",
       "      <td>5.654067</td>\n",
       "      <td>3.547199</td>\n",
       "      <td>0.304828</td>\n",
       "      <td>3.547199</td>\n",
       "      <td>4.949292</td>\n",
       "      <td>5.138249</td>\n",
       "      <td>5.344579</td>\n",
       "      <td>537.621115</td>\n",
       "      <td>1376.406977</td>\n",
       "      <td>...</td>\n",
       "      <td>28.839210</td>\n",
       "      <td>28.964675</td>\n",
       "      <td>-90.096276</td>\n",
       "      <td>-89.84271</td>\n",
       "      <td>-90.23363</td>\n",
       "      <td>0.116995</td>\n",
       "      <td>-90.23363</td>\n",
       "      <td>-90.207423</td>\n",
       "      <td>-90.126710</td>\n",
       "      <td>-90.001112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301704</th>\n",
       "      <td>7.070819</td>\n",
       "      <td>8.183824</td>\n",
       "      <td>5.002604</td>\n",
       "      <td>0.481781</td>\n",
       "      <td>5.002604</td>\n",
       "      <td>6.905803</td>\n",
       "      <td>7.075561</td>\n",
       "      <td>7.343370</td>\n",
       "      <td>665.507580</td>\n",
       "      <td>2086.436941</td>\n",
       "      <td>...</td>\n",
       "      <td>30.299550</td>\n",
       "      <td>30.479425</td>\n",
       "      <td>-88.062989</td>\n",
       "      <td>-88.01349</td>\n",
       "      <td>-88.25952</td>\n",
       "      <td>0.060417</td>\n",
       "      <td>-88.03209</td>\n",
       "      <td>-88.077433</td>\n",
       "      <td>-88.032710</td>\n",
       "      <td>-88.024760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301705</th>\n",
       "      <td>6.347115</td>\n",
       "      <td>7.236027</td>\n",
       "      <td>4.581902</td>\n",
       "      <td>0.774160</td>\n",
       "      <td>4.581902</td>\n",
       "      <td>5.489919</td>\n",
       "      <td>6.789326</td>\n",
       "      <td>6.918124</td>\n",
       "      <td>667.499729</td>\n",
       "      <td>2691.125046</td>\n",
       "      <td>...</td>\n",
       "      <td>28.680210</td>\n",
       "      <td>28.813140</td>\n",
       "      <td>-89.321703</td>\n",
       "      <td>-89.12329</td>\n",
       "      <td>-89.43168</td>\n",
       "      <td>0.094813</td>\n",
       "      <td>-89.42465</td>\n",
       "      <td>-89.420075</td>\n",
       "      <td>-89.348480</td>\n",
       "      <td>-89.232665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>301706 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        speed_mean  speed_max  speed_min  speed_std  speed_mode  speed_q1  \\\n",
       "0         1.849572   2.044116   1.495934   0.090731    1.839331  1.795889   \n",
       "1         1.243128   4.468756   0.000000   1.325308    0.000000  0.030436   \n",
       "2         1.754980  10.152139   0.000000   3.110417    0.000000  0.024849   \n",
       "3         0.054933   0.528916   0.004212   0.048892    0.024173  0.026561   \n",
       "4         3.108983   7.442290   0.000000   2.851432    0.015885  0.255487   \n",
       "...            ...        ...        ...        ...         ...       ...   \n",
       "301701    6.299446   6.930492   4.685812   0.522108    4.685812  5.944622   \n",
       "301702    6.189746   6.821701   3.443472   0.644929    3.443472  6.044247   \n",
       "301703    5.137518   5.654067   3.547199   0.304828    3.547199  4.949292   \n",
       "301704    7.070819   8.183824   5.002604   0.481781    5.002604  6.905803   \n",
       "301705    6.347115   7.236027   4.581902   0.774160    4.581902  5.489919   \n",
       "\n",
       "        speed_q2  speed_q3  distance_mean  distance_max  ...     lat_q2  \\\n",
       "0       1.856550  1.911966     135.071257    264.140849  ...  30.301030   \n",
       "1       1.227719  1.544401     145.142859   2841.874087  ...  28.999880   \n",
       "2       0.244928  1.120400     120.601385   2065.622075  ...  29.243710   \n",
       "3       0.045788  0.065964      10.568758     81.068426  ...  28.822280   \n",
       "4       2.427915  6.065710     216.861544   2717.328784  ...  30.167670   \n",
       "...          ...       ...            ...           ...  ...        ...   \n",
       "301701  6.576137  6.680766     681.770504   2844.183786  ...  28.651085   \n",
       "301702  6.441361  6.587360     574.446311   1785.005854  ...  28.638040   \n",
       "301703  5.138249  5.344579     537.621115   1376.406977  ...  28.839210   \n",
       "301704  7.075561  7.343370     665.507580   2086.436941  ...  30.299550   \n",
       "301705  6.789326  6.918124     667.499729   2691.125046  ...  28.680210   \n",
       "\n",
       "           lat_q3   lon_mean   lon_max   lon_min   lon_std  lon_mode  \\\n",
       "0       30.362690 -87.903259 -87.76132 -87.99302  0.068003 -87.99302   \n",
       "1       29.020655 -91.502626 -91.23235 -91.85809  0.224377 -91.32419   \n",
       "2       29.247860 -91.404438 -91.36791 -91.47050  0.028035 -91.39651   \n",
       "3       28.822770 -89.333770 -89.33024 -89.33521  0.001293 -89.33479   \n",
       "4       30.180550 -88.744727 -88.54420 -88.88934  0.131171 -88.88031   \n",
       "...           ...        ...       ...       ...       ...       ...   \n",
       "301701  28.798198 -89.308369 -89.08625 -89.43154  0.104131 -89.43154   \n",
       "301702  28.790492 -89.325142 -89.16524 -89.43129  0.079961 -89.42653   \n",
       "301703  28.964675 -90.096276 -89.84271 -90.23363  0.116995 -90.23363   \n",
       "301704  30.479425 -88.062989 -88.01349 -88.25952  0.060417 -88.03209   \n",
       "301705  28.813140 -89.321703 -89.12329 -89.43168  0.094813 -89.42465   \n",
       "\n",
       "           lon_q1     lon_q2     lon_q3  \n",
       "0      -87.960960 -87.922550 -87.848695  \n",
       "1      -91.768765 -91.328140 -91.324105  \n",
       "2      -91.410160 -91.396490 -91.387170  \n",
       "3      -89.334740 -89.334340 -89.333300  \n",
       "4      -88.879640 -88.776920 -88.601815  \n",
       "...           ...        ...        ...  \n",
       "301701 -89.416560 -89.323005 -89.211875  \n",
       "301702 -89.414905 -89.320230 -89.266795  \n",
       "301703 -90.207423 -90.126710 -90.001112  \n",
       "301704 -88.077433 -88.032710 -88.024760  \n",
       "301705 -89.420075 -89.348480 -89.232665  \n",
       "\n",
       "[301706 rows x 48 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_features(row):\n",
    "#     elapsed = np.array(row['elapsed_s'])\n",
    "#     lat = np.array(row['LAT'])\n",
    "#     lon = np.array(row['LON'])\n",
    "\n",
    "#     # Calculate duration\n",
    "#     duration = elapsed[-1] - elapsed[0]\n",
    "\n",
    "#     # Convert degrees to radians for Haversine formula\n",
    "#     lat_rad = np.deg2rad(lat)\n",
    "#     lon_rad = np.deg2rad(lon)\n",
    "\n",
    "#     # Earth's radius (in km)\n",
    "#     R = 6371.0\n",
    "\n",
    "#     # Compute deltas\n",
    "#     delta_lat = np.diff(lat_rad)\n",
    "#     delta_lon = np.diff(lon_rad)\n",
    "\n",
    "#     # Haversine formula\n",
    "#     a = np.sin(delta_lat / 2.0) ** 2 + \\\n",
    "#         np.cos(lat_rad[:-1]) * np.cos(lat_rad[1:]) * np.sin(delta_lon / 2.0) ** 2\n",
    "#     c = 2 * np.arcsin(np.sqrt(a))\n",
    "#     distance = R * c  # distance between each consecutive point in km\n",
    "\n",
    "#     # Time deltas (in seconds)\n",
    "#     dt = np.diff(elapsed) + 1e-10\n",
    "    \n",
    "\n",
    "#     # Speed in km/h\n",
    "#     # speeds = distance / (dt / 3600.0)\n",
    "#     speeds = distance / dt\n",
    "\n",
    "#     # Pad to align with original size\n",
    "#     speeds = np.insert(speeds, 0, 0.0)\n",
    "\n",
    "#     # Acceleration (km/h²)\n",
    "#     accel = np.diff(speeds) / dt \n",
    "#     # accel = np.diff(speeds) / (dt[1:] / 3600.0) if len(speeds) > 1 else np.array([0.0])\n",
    "#     accel = np.insert(accel, 0, 0.0)\n",
    "\n",
    "#     return pd.Series({\n",
    "#         'duration': duration,\n",
    "#         'lat_mean': lat.mean(),\n",
    "#         'lon_mean': lon.mean(),\n",
    "#         'lat_std': lat.std(),\n",
    "#         'lon_std': lon.std(),\n",
    "#         'lat_median': np.median(lat),\n",
    "#         'lon_median': np.median(lon),\n",
    "#         'lat_min': lat.min(),\n",
    "#         'lon_min': lon.min(),\n",
    "#         'lat_max': lat.max(),\n",
    "#         'lon_max': lon.max(),\n",
    "#         'lat_range': lat.max() - lat.min(),\n",
    "#         'lon_range': lon.max() - lon.min(),\n",
    "#         'bbox_area': (lat.max() - lat.min()) * (lon.max() - lon.min()),\n",
    "#         'start_lat': lat[0],\n",
    "#         'start_lon': lon[0],\n",
    "#         'end_lat': lat[-1],\n",
    "#         'end_lon': lon[-1],\n",
    "#         'speed_mean': speeds.mean(),\n",
    "#         'speed_max': speeds.max(),\n",
    "#         'speed_std': speeds.std(),\n",
    "#         'accel_mean': accel.mean(),\n",
    "#         'accel_std': accel.std(),\n",
    "#         'accel_max': accel.max(),\n",
    "#     })\n",
    "\n",
    "# features = segmented_df.apply(extract_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MMSI</th>\n",
       "      <th>VesselType</th>\n",
       "      <th>Label</th>\n",
       "      <th>elapsed_s</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>367659930</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 69, 138, 210, 279, 349, 420, 488, 570, 639...</td>\n",
       "      <td>[30.4289, 30.42774, 30.42675, 30.42573, 30.424...</td>\n",
       "      <td>[-87.99302, -87.99258, -87.9919, -87.99129, -8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>367553360</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 70, 149, 220, 301, 379, 449, 559, 630, 709...</td>\n",
       "      <td>[29.01648, 29.01666, 29.01664, 29.01661, 29.01...</td>\n",
       "      <td>[-91.83069, -91.83175, -91.83304, -91.83416, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>367461560</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 65, 131, 197, 263, 335, 402, 467, 533, 600...</td>\n",
       "      <td>[29.38964, 29.38584, 29.38206, 29.37743, 29.37...</td>\n",
       "      <td>[-91.36791, -91.37142, -91.37496, -91.37891, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>538007067</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 120, 301, 483, 662, 843, 1023, 1204, 1383,...</td>\n",
       "      <td>[28.82299, 28.82325, 28.8236, 28.82388, 28.824...</td>\n",
       "      <td>[-89.33299, -89.33357, -89.3343, -89.33491, -8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>369053000</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 70, 139, 209, 270, 340, 410, 473, 540, 610...</td>\n",
       "      <td>[30.18058, 30.17847, 30.17641, 30.17425, 30.17...</td>\n",
       "      <td>[-88.56405, -88.56745, -88.57083, -88.57432, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301701</th>\n",
       "      <td>538006166</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 81, 224, 301, 401, 510, 581, 651, 750, 831...</td>\n",
       "      <td>[28.91509, 28.91185, 28.90624, 28.90286, 28.89...</td>\n",
       "      <td>[-89.42226, -89.42518, -89.43059, -89.43154, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301702</th>\n",
       "      <td>538005865</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 69, 130, 337, 440, 620, 681, 811, 891, 104...</td>\n",
       "      <td>[28.91911, 28.91597, 28.91333, 28.90537, 28.90...</td>\n",
       "      <td>[-89.4197, -89.422, -89.4239, -89.43129, -89.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301703</th>\n",
       "      <td>369293000</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 100, 230, 309, 391, 480, 741, 811, 879, 90...</td>\n",
       "      <td>[29.07654, 29.07338, 29.06873, 29.06566, 29.06...</td>\n",
       "      <td>[-90.22863, -90.22913, -90.22987, -90.23059, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301704</th>\n",
       "      <td>636017526</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 90, 161, 240, 307, 433, 498, 565, 636, 715...</td>\n",
       "      <td>[30.64235, 30.63707, 30.63251, 30.6274, 30.622...</td>\n",
       "      <td>[-88.03225, -88.03235, -88.03236, -88.03249, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301705</th>\n",
       "      <td>538004384</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 70, 250, 317, 380, 417, 480, 560, 631, 701...</td>\n",
       "      <td>[28.91971, 28.91616, 28.90798, 28.90495, 28.90...</td>\n",
       "      <td>[-89.41942, -89.42204, -89.42903, -89.43138, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>301706 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             MMSI  VesselType  Label  \\\n",
       "0       367659930        31.0      0   \n",
       "1       367553360        30.0      0   \n",
       "2       367461560        90.0      0   \n",
       "3       538007067        70.0      0   \n",
       "4       369053000        90.0      0   \n",
       "...           ...         ...    ...   \n",
       "301701  538006166        80.0      0   \n",
       "301702  538005865        80.0      0   \n",
       "301703  369293000        90.0      0   \n",
       "301704  636017526        70.0      0   \n",
       "301705  538004384        70.0      0   \n",
       "\n",
       "                                                elapsed_s  \\\n",
       "0       [0, 69, 138, 210, 279, 349, 420, 488, 570, 639...   \n",
       "1       [0, 70, 149, 220, 301, 379, 449, 559, 630, 709...   \n",
       "2       [0, 65, 131, 197, 263, 335, 402, 467, 533, 600...   \n",
       "3       [0, 120, 301, 483, 662, 843, 1023, 1204, 1383,...   \n",
       "4       [0, 70, 139, 209, 270, 340, 410, 473, 540, 610...   \n",
       "...                                                   ...   \n",
       "301701  [0, 81, 224, 301, 401, 510, 581, 651, 750, 831...   \n",
       "301702  [0, 69, 130, 337, 440, 620, 681, 811, 891, 104...   \n",
       "301703  [0, 100, 230, 309, 391, 480, 741, 811, 879, 90...   \n",
       "301704  [0, 90, 161, 240, 307, 433, 498, 565, 636, 715...   \n",
       "301705  [0, 70, 250, 317, 380, 417, 480, 560, 631, 701...   \n",
       "\n",
       "                                                      LAT  \\\n",
       "0       [30.4289, 30.42774, 30.42675, 30.42573, 30.424...   \n",
       "1       [29.01648, 29.01666, 29.01664, 29.01661, 29.01...   \n",
       "2       [29.38964, 29.38584, 29.38206, 29.37743, 29.37...   \n",
       "3       [28.82299, 28.82325, 28.8236, 28.82388, 28.824...   \n",
       "4       [30.18058, 30.17847, 30.17641, 30.17425, 30.17...   \n",
       "...                                                   ...   \n",
       "301701  [28.91509, 28.91185, 28.90624, 28.90286, 28.89...   \n",
       "301702  [28.91911, 28.91597, 28.91333, 28.90537, 28.90...   \n",
       "301703  [29.07654, 29.07338, 29.06873, 29.06566, 29.06...   \n",
       "301704  [30.64235, 30.63707, 30.63251, 30.6274, 30.622...   \n",
       "301705  [28.91971, 28.91616, 28.90798, 28.90495, 28.90...   \n",
       "\n",
       "                                                      LON  \n",
       "0       [-87.99302, -87.99258, -87.9919, -87.99129, -8...  \n",
       "1       [-91.83069, -91.83175, -91.83304, -91.83416, -...  \n",
       "2       [-91.36791, -91.37142, -91.37496, -91.37891, -...  \n",
       "3       [-89.33299, -89.33357, -89.3343, -89.33491, -8...  \n",
       "4       [-88.56405, -88.56745, -88.57083, -88.57432, -...  \n",
       "...                                                   ...  \n",
       "301701  [-89.42226, -89.42518, -89.43059, -89.43154, -...  \n",
       "301702  [-89.4197, -89.422, -89.4239, -89.43129, -89.4...  \n",
       "301703  [-90.22863, -90.22913, -90.22987, -90.23059, -...  \n",
       "301704  [-88.03225, -88.03235, -88.03236, -88.03249, -...  \n",
       "301705  [-89.41942, -89.42204, -89.42903, -89.43138, -...  \n",
       "\n",
       "[301706 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmented_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speed_mean</th>\n",
       "      <th>speed_max</th>\n",
       "      <th>speed_min</th>\n",
       "      <th>speed_std</th>\n",
       "      <th>speed_mode</th>\n",
       "      <th>speed_q1</th>\n",
       "      <th>speed_q2</th>\n",
       "      <th>speed_q3</th>\n",
       "      <th>distance_mean</th>\n",
       "      <th>distance_max</th>\n",
       "      <th>...</th>\n",
       "      <th>lat_q3</th>\n",
       "      <th>lon_mean</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_std</th>\n",
       "      <th>lon_mode</th>\n",
       "      <th>lon_q1</th>\n",
       "      <th>lon_q2</th>\n",
       "      <th>lon_q3</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.849572</td>\n",
       "      <td>2.044116</td>\n",
       "      <td>1.495934</td>\n",
       "      <td>0.090731</td>\n",
       "      <td>1.839331</td>\n",
       "      <td>1.795889</td>\n",
       "      <td>1.856550</td>\n",
       "      <td>1.911966</td>\n",
       "      <td>135.071257</td>\n",
       "      <td>264.140849</td>\n",
       "      <td>...</td>\n",
       "      <td>30.362690</td>\n",
       "      <td>-87.903259</td>\n",
       "      <td>-87.76132</td>\n",
       "      <td>-87.99302</td>\n",
       "      <td>0.068003</td>\n",
       "      <td>-87.99302</td>\n",
       "      <td>-87.960960</td>\n",
       "      <td>-87.922550</td>\n",
       "      <td>-87.848695</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.243128</td>\n",
       "      <td>4.468756</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.325308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030436</td>\n",
       "      <td>1.227719</td>\n",
       "      <td>1.544401</td>\n",
       "      <td>145.142859</td>\n",
       "      <td>2841.874087</td>\n",
       "      <td>...</td>\n",
       "      <td>29.020655</td>\n",
       "      <td>-91.502626</td>\n",
       "      <td>-91.23235</td>\n",
       "      <td>-91.85809</td>\n",
       "      <td>0.224377</td>\n",
       "      <td>-91.32419</td>\n",
       "      <td>-91.768765</td>\n",
       "      <td>-91.328140</td>\n",
       "      <td>-91.324105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.754980</td>\n",
       "      <td>10.152139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.110417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024849</td>\n",
       "      <td>0.244928</td>\n",
       "      <td>1.120400</td>\n",
       "      <td>120.601385</td>\n",
       "      <td>2065.622075</td>\n",
       "      <td>...</td>\n",
       "      <td>29.247860</td>\n",
       "      <td>-91.404438</td>\n",
       "      <td>-91.36791</td>\n",
       "      <td>-91.47050</td>\n",
       "      <td>0.028035</td>\n",
       "      <td>-91.39651</td>\n",
       "      <td>-91.410160</td>\n",
       "      <td>-91.396490</td>\n",
       "      <td>-91.387170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.054933</td>\n",
       "      <td>0.528916</td>\n",
       "      <td>0.004212</td>\n",
       "      <td>0.048892</td>\n",
       "      <td>0.024173</td>\n",
       "      <td>0.026561</td>\n",
       "      <td>0.045788</td>\n",
       "      <td>0.065964</td>\n",
       "      <td>10.568758</td>\n",
       "      <td>81.068426</td>\n",
       "      <td>...</td>\n",
       "      <td>28.822770</td>\n",
       "      <td>-89.333770</td>\n",
       "      <td>-89.33024</td>\n",
       "      <td>-89.33521</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>-89.33479</td>\n",
       "      <td>-89.334740</td>\n",
       "      <td>-89.334340</td>\n",
       "      <td>-89.333300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.108983</td>\n",
       "      <td>7.442290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.851432</td>\n",
       "      <td>0.015885</td>\n",
       "      <td>0.255487</td>\n",
       "      <td>2.427915</td>\n",
       "      <td>6.065710</td>\n",
       "      <td>216.861544</td>\n",
       "      <td>2717.328784</td>\n",
       "      <td>...</td>\n",
       "      <td>30.180550</td>\n",
       "      <td>-88.744727</td>\n",
       "      <td>-88.54420</td>\n",
       "      <td>-88.88934</td>\n",
       "      <td>0.131171</td>\n",
       "      <td>-88.88031</td>\n",
       "      <td>-88.879640</td>\n",
       "      <td>-88.776920</td>\n",
       "      <td>-88.601815</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301701</th>\n",
       "      <td>6.299446</td>\n",
       "      <td>6.930492</td>\n",
       "      <td>4.685812</td>\n",
       "      <td>0.522108</td>\n",
       "      <td>4.685812</td>\n",
       "      <td>5.944622</td>\n",
       "      <td>6.576137</td>\n",
       "      <td>6.680766</td>\n",
       "      <td>681.770504</td>\n",
       "      <td>2844.183786</td>\n",
       "      <td>...</td>\n",
       "      <td>28.798198</td>\n",
       "      <td>-89.308369</td>\n",
       "      <td>-89.08625</td>\n",
       "      <td>-89.43154</td>\n",
       "      <td>0.104131</td>\n",
       "      <td>-89.43154</td>\n",
       "      <td>-89.416560</td>\n",
       "      <td>-89.323005</td>\n",
       "      <td>-89.211875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301702</th>\n",
       "      <td>6.189746</td>\n",
       "      <td>6.821701</td>\n",
       "      <td>3.443472</td>\n",
       "      <td>0.644929</td>\n",
       "      <td>3.443472</td>\n",
       "      <td>6.044247</td>\n",
       "      <td>6.441361</td>\n",
       "      <td>6.587360</td>\n",
       "      <td>574.446311</td>\n",
       "      <td>1785.005854</td>\n",
       "      <td>...</td>\n",
       "      <td>28.790492</td>\n",
       "      <td>-89.325142</td>\n",
       "      <td>-89.16524</td>\n",
       "      <td>-89.43129</td>\n",
       "      <td>0.079961</td>\n",
       "      <td>-89.42653</td>\n",
       "      <td>-89.414905</td>\n",
       "      <td>-89.320230</td>\n",
       "      <td>-89.266795</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301703</th>\n",
       "      <td>5.137518</td>\n",
       "      <td>5.654067</td>\n",
       "      <td>3.547199</td>\n",
       "      <td>0.304828</td>\n",
       "      <td>3.547199</td>\n",
       "      <td>4.949292</td>\n",
       "      <td>5.138249</td>\n",
       "      <td>5.344579</td>\n",
       "      <td>537.621115</td>\n",
       "      <td>1376.406977</td>\n",
       "      <td>...</td>\n",
       "      <td>28.964675</td>\n",
       "      <td>-90.096276</td>\n",
       "      <td>-89.84271</td>\n",
       "      <td>-90.23363</td>\n",
       "      <td>0.116995</td>\n",
       "      <td>-90.23363</td>\n",
       "      <td>-90.207423</td>\n",
       "      <td>-90.126710</td>\n",
       "      <td>-90.001112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301704</th>\n",
       "      <td>7.070819</td>\n",
       "      <td>8.183824</td>\n",
       "      <td>5.002604</td>\n",
       "      <td>0.481781</td>\n",
       "      <td>5.002604</td>\n",
       "      <td>6.905803</td>\n",
       "      <td>7.075561</td>\n",
       "      <td>7.343370</td>\n",
       "      <td>665.507580</td>\n",
       "      <td>2086.436941</td>\n",
       "      <td>...</td>\n",
       "      <td>30.479425</td>\n",
       "      <td>-88.062989</td>\n",
       "      <td>-88.01349</td>\n",
       "      <td>-88.25952</td>\n",
       "      <td>0.060417</td>\n",
       "      <td>-88.03209</td>\n",
       "      <td>-88.077433</td>\n",
       "      <td>-88.032710</td>\n",
       "      <td>-88.024760</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301705</th>\n",
       "      <td>6.347115</td>\n",
       "      <td>7.236027</td>\n",
       "      <td>4.581902</td>\n",
       "      <td>0.774160</td>\n",
       "      <td>4.581902</td>\n",
       "      <td>5.489919</td>\n",
       "      <td>6.789326</td>\n",
       "      <td>6.918124</td>\n",
       "      <td>667.499729</td>\n",
       "      <td>2691.125046</td>\n",
       "      <td>...</td>\n",
       "      <td>28.813140</td>\n",
       "      <td>-89.321703</td>\n",
       "      <td>-89.12329</td>\n",
       "      <td>-89.43168</td>\n",
       "      <td>0.094813</td>\n",
       "      <td>-89.42465</td>\n",
       "      <td>-89.420075</td>\n",
       "      <td>-89.348480</td>\n",
       "      <td>-89.232665</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>301706 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        speed_mean  speed_max  speed_min  speed_std  speed_mode  speed_q1  \\\n",
       "0         1.849572   2.044116   1.495934   0.090731    1.839331  1.795889   \n",
       "1         1.243128   4.468756   0.000000   1.325308    0.000000  0.030436   \n",
       "2         1.754980  10.152139   0.000000   3.110417    0.000000  0.024849   \n",
       "3         0.054933   0.528916   0.004212   0.048892    0.024173  0.026561   \n",
       "4         3.108983   7.442290   0.000000   2.851432    0.015885  0.255487   \n",
       "...            ...        ...        ...        ...         ...       ...   \n",
       "301701    6.299446   6.930492   4.685812   0.522108    4.685812  5.944622   \n",
       "301702    6.189746   6.821701   3.443472   0.644929    3.443472  6.044247   \n",
       "301703    5.137518   5.654067   3.547199   0.304828    3.547199  4.949292   \n",
       "301704    7.070819   8.183824   5.002604   0.481781    5.002604  6.905803   \n",
       "301705    6.347115   7.236027   4.581902   0.774160    4.581902  5.489919   \n",
       "\n",
       "        speed_q2  speed_q3  distance_mean  distance_max  ...     lat_q3  \\\n",
       "0       1.856550  1.911966     135.071257    264.140849  ...  30.362690   \n",
       "1       1.227719  1.544401     145.142859   2841.874087  ...  29.020655   \n",
       "2       0.244928  1.120400     120.601385   2065.622075  ...  29.247860   \n",
       "3       0.045788  0.065964      10.568758     81.068426  ...  28.822770   \n",
       "4       2.427915  6.065710     216.861544   2717.328784  ...  30.180550   \n",
       "...          ...       ...            ...           ...  ...        ...   \n",
       "301701  6.576137  6.680766     681.770504   2844.183786  ...  28.798198   \n",
       "301702  6.441361  6.587360     574.446311   1785.005854  ...  28.790492   \n",
       "301703  5.138249  5.344579     537.621115   1376.406977  ...  28.964675   \n",
       "301704  7.075561  7.343370     665.507580   2086.436941  ...  30.479425   \n",
       "301705  6.789326  6.918124     667.499729   2691.125046  ...  28.813140   \n",
       "\n",
       "         lon_mean   lon_max   lon_min   lon_std  lon_mode     lon_q1  \\\n",
       "0      -87.903259 -87.76132 -87.99302  0.068003 -87.99302 -87.960960   \n",
       "1      -91.502626 -91.23235 -91.85809  0.224377 -91.32419 -91.768765   \n",
       "2      -91.404438 -91.36791 -91.47050  0.028035 -91.39651 -91.410160   \n",
       "3      -89.333770 -89.33024 -89.33521  0.001293 -89.33479 -89.334740   \n",
       "4      -88.744727 -88.54420 -88.88934  0.131171 -88.88031 -88.879640   \n",
       "...           ...       ...       ...       ...       ...        ...   \n",
       "301701 -89.308369 -89.08625 -89.43154  0.104131 -89.43154 -89.416560   \n",
       "301702 -89.325142 -89.16524 -89.43129  0.079961 -89.42653 -89.414905   \n",
       "301703 -90.096276 -89.84271 -90.23363  0.116995 -90.23363 -90.207423   \n",
       "301704 -88.062989 -88.01349 -88.25952  0.060417 -88.03209 -88.077433   \n",
       "301705 -89.321703 -89.12329 -89.43168  0.094813 -89.42465 -89.420075   \n",
       "\n",
       "           lon_q2     lon_q3  Label  \n",
       "0      -87.922550 -87.848695      0  \n",
       "1      -91.328140 -91.324105      0  \n",
       "2      -91.396490 -91.387170      0  \n",
       "3      -89.334340 -89.333300      0  \n",
       "4      -88.776920 -88.601815      0  \n",
       "...           ...        ...    ...  \n",
       "301701 -89.323005 -89.211875      0  \n",
       "301702 -89.320230 -89.266795      0  \n",
       "301703 -90.126710 -90.001112      0  \n",
       "301704 -88.032710 -88.024760      0  \n",
       "301705 -89.348480 -89.232665      0  \n",
       "\n",
       "[301706 rows x 49 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve,\n",
    "    f1_score,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "\n",
    "# --- Data Preparation ---\n",
    "# Assuming 'features_df' and 'segmented_df' are already defined.\n",
    "# If not, dummy data is created for demonstration purposes.\n",
    "\n",
    "# X = features_df\n",
    "time_cols = [c for c in features_df.columns if c.startswith(\"time\")]\n",
    "# X = features_df.drop(columns='Label')\n",
    "# drop both Label and all those time-columns\n",
    "X = features_df.drop(columns= time_cols)\n",
    "y = segmented_df['Label']\n",
    "\n",
    "\n",
    "# 1) Split into train+val (80%) and test (20%)\n",
    "# Stratify ensures that the proportion of target variable 'y' is the same in all splits.\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y,\n",
    "    stratify=y,\n",
    "    test_size=0.20,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2) Split train+val into train (60%) and val (20%)\n",
    "# Since X_temp is 80%, using test_size=0.25 on it gives 0.25 * 0.8 = 0.20 overall\n",
    "X_train_orig, X_val, y_train_orig, y_val = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    stratify=y_temp,\n",
    "    test_size=0.25,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Define the base classifier.\n",
    "# class_weight='balanced' automatically adjusts weights inversely proportional to class frequencies.\n",
    "base_clf = RandomForestClassifier(\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_estimators=100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Function to Train, Tune Threshold, and Evaluate ---\n",
    "def train_tune_evaluate(X_train, y_train, X_val, y_val, X_test, y_test, classifier, sampling_strategy_name):\n",
    "    \"\"\"\n",
    "    Trains a classifier, tunes its probability threshold on a validation set,\n",
    "    and reports its performance on a test set.\n",
    "\n",
    "    Args:\n",
    "        X_train (pd.DataFrame): Training features.\n",
    "        y_train (pd.Series): Training labels.\n",
    "        X_val (pd.DataFrame): Validation features (for threshold tuning).\n",
    "        y_val (pd.Series): Validation labels (for threshold tuning).\n",
    "        X_test (pd.DataFrame): Test features (for final evaluation).\n",
    "        y_test (pd.Series): Test labels (for final evaluation).\n",
    "        classifier (sklearn.base.Estimator): The machine learning classifier to use.\n",
    "        sampling_strategy_name (str): A descriptive name for the current sampling strategy\n",
    "                                      (e.g., \"Original Distribution\", \"Undersampled\", \"Oversampled\").\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*50}\\n--- Results for {sampling_strategy_name} Training Data ---\\n{'='*50}\")\n",
    "\n",
    "    clf = classifier.__class__(**classifier.get_params()) # Create a fresh instance to avoid retraining issues\n",
    "    \n",
    "    # Train the classifier on the provided training data\n",
    "    print(f\"Training classifier on {len(X_train)} samples...\")\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "    # Get probability scores for the validation set\n",
    "    val_scores = clf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Compute Precision-Recall curve to find the best threshold\n",
    "    precision, recall, thresholds = precision_recall_curve(y_val, val_scores)\n",
    "\n",
    "    # Calculate F1-score for each threshold to identify the optimal one\n",
    "    # Add a small epsilon (1e-6) to prevent division by zero for F1 calculation\n",
    "    f1_scores = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1] + 1e-6)\n",
    "\n",
    "    # Find the threshold that yields the highest F1-score on the validation set\n",
    "    best_idx = np.argmax(f1_scores)\n",
    "    best_threshold = thresholds[best_idx]\n",
    "    best_f1_val = f1_scores[best_idx]\n",
    "\n",
    "    print(f\"\\nBest validation threshold = {best_threshold:.4f} (F1-score = {best_f1_val:.4f})\")\n",
    "\n",
    "    # Evaluate the classifier on the unseen test set using the best threshold found\n",
    "    test_scores = clf.predict_proba(X_test)[:, 1]\n",
    "    y_test_pred = (test_scores >= best_threshold).astype(int)\n",
    "\n",
    "    print(f\"\\n--- Classification Report on Test Set @ Threshold {best_threshold:.4f} ---\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "    return clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "--- Results for Original Distribution Training Data ---\n",
      "==================================================\n",
      "Training classifier on 181023 samples...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from joblib import dump\n",
    "\n",
    "# make a directory for your models\n",
    "os.makedirs(\"saved_models\", exist_ok=True)\n",
    "\n",
    "# Scenario 1: Original Distribution\n",
    "model_orig = train_tune_evaluate(\n",
    "    X_train_orig, y_train_orig,\n",
    "    X_val, y_val,\n",
    "    X_test, y_test,\n",
    "    base_clf,\n",
    "    \"Original Distribution\"\n",
    ")\n",
    "dump(model_orig, \"saved_models/model_original_distribution.joblib\")\n",
    "print(\"Saved Original Distribution model to saved_models/model_original_distribution.joblib\")\n",
    "\n",
    "# Scenario 2: Undersampled Training Data\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_train_under, y_train_under = undersampler.fit_resample(X_train_orig, y_train_orig)\n",
    "\n",
    "model_under = train_tune_evaluate(\n",
    "    X_train_under, y_train_under,\n",
    "    X_val, y_val,\n",
    "    X_test, y_test,\n",
    "    base_clf,\n",
    "    \"Undersampled\"\n",
    ")\n",
    "dump(model_under, \"saved_models/model_undersampled.joblib\")\n",
    "print(\"Saved Undersampled model to saved_models/model_undersampled.joblib\")\n",
    "\n",
    "# Scenario 3: Oversampled Training Data\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_train_over, y_train_over = oversampler.fit_resample(X_train_orig, y_train_orig)\n",
    "\n",
    "model_over = train_tune_evaluate(\n",
    "    X_train_over, y_train_over,\n",
    "    X_val, y_val,\n",
    "    X_test, y_test,\n",
    "    base_clf,\n",
    "    \"Oversampled\"\n",
    ")\n",
    "dump(model_over, \"saved_models/model_oversampled.joblib\")\n",
    "print(\"Saved Oversampled model to saved_models/model_oversampled.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "model = load(\"saved_models/model_undersampled.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)\n",
    " # Check the type of the loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy: 2.2.4\n",
      "Pandas: 2.2.3\n",
      "SciPy: 1.15.2\n",
      "sklearn: 1.6.1\n"
     ]
    }
   ],
   "source": [
    "import numpy, pandas, scipy, sklearn\n",
    "print(\"NumPy:\",  numpy.__version__)\n",
    "print(\"Pandas:\", pandas.__version__)\n",
    "print(\"SciPy:\",  scipy.__version__)\n",
    "print(\"sklearn:\", sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# ── 0) Oversample if needed ───────────────────────────────────────────────────\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_train_over, y_train_over = oversampler.fit_resample(X_train_orig, y_train_orig)\n",
    "\n",
    "# ── 1) Define base learners ────────────────────────────────────────────────────\n",
    "# Tree-based\n",
    "rf  = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n",
    "et  = ExtraTreesClassifier(n_estimators=50, n_jobs=-1, random_state=42)\n",
    "gb  = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Distance-based\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Probabilistic\n",
    "nb  = make_pipeline(StandardScaler(), GaussianNB())\n",
    "\n",
    "# Linear / margin-based\n",
    "lr  = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000, random_state=42))\n",
    "# svm = make_pipeline(StandardScaler(), SVC(kernel=\"rbf\", probability=True, random_state=42))\n",
    "\n",
    "# ── 2) Voting ensemble ────────────────────────────────────────────────────────\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"rf\",  rf),\n",
    "        (\"et\",  et),\n",
    "        (\"gb\",  gb),\n",
    "        (\"knn\", knn),\n",
    "        (\"nb\",  nb),\n",
    "        (\"lr\",  lr),\n",
    "        # (\"svm\", svm),\n",
    "    ],\n",
    "    voting=\"soft\",          # average predicted probabilities\n",
    "    # weights=[2,1,1,1,1,1,1], # give RF a bit more say\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# ── 3) Fit & evaluate ─────────────────────────────────────────────────────────\n",
    "voting_clf.fit(X_train_over, y_train_over)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get probability scores for the validation set\n",
    "val_scores = voting_clf.predict_proba(X_val)[:, 1]\n",
    "# val_scores = rf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Compute Precision-Recall curve to find the best threshold\n",
    "precision, recall, thresholds = precision_recall_curve(y_val, val_scores)\n",
    "\n",
    "# Calculate F1-score for each threshold to identify the optimal one\n",
    "# Add a small epsilon (1e-6) to prevent division by zero for F1 calculation\n",
    "f1_scores = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1] + 1e-6)\n",
    "\n",
    "# Find the threshold that yields the highest F1-score on the validation set\n",
    "best_idx = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_idx]\n",
    "best_f1_val = f1_scores[best_idx]\n",
    "\n",
    "print(f\"\\nBest validation threshold = {best_threshold:.4f} (F1-score = {best_f1_val:.4f})\")\n",
    "\n",
    "# Evaluate the classifier on the unseen test set using the best threshold found\n",
    "test_scores = voting_clf.predict_proba(X_test)[:, 1]\n",
    "y_test_pred = (test_scores >= best_threshold).astype(int)\n",
    "\n",
    "print(f\"\\n--- Classification Report on Test Set @ Threshold {best_threshold:.4f} ---\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 3) Stacked Generalization ─────────────────────────────────────────────────\n",
    "stack_clf = StackingClassifier(\n",
    "    estimators=[(\"rf\", rf), (\"svm\", svm), (\"lr\", lr)],\n",
    "    final_estimator=LogisticRegression(max_iter=1000, random_state=42),\n",
    "    cv=5,\n",
    "    stack_method=\"predict_proba\"\n",
    ")\n",
    "\n",
    "# Fit on train\n",
    "stack_clf.fit(X_train_over, y_train_over)\n",
    "\n",
    "# Evaluate on validation\n",
    "y_val_pred_stack = stack_clf.predict(X_val)\n",
    "print(\"Stacking Ensemble — Val Accuracy:\", accuracy_score(y_val, y_val_pred_stack))\n",
    "print(classification_report(y_val, y_val_pred_stack))\n",
    "\n",
    "# ── 4) Final Test-Set Evaluation ─────────────────────────────────────────────\n",
    "for name, model, y_pred in [\n",
    "    (\"Voting\", voting_clf, voting_clf.predict(X_test)),\n",
    "    (\"Stacking\", stack_clf, stack_clf.predict(X_test)),\n",
    "]:\n",
    "    print(f\"\\n{name} Ensemble — Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve,\n",
    "    f1_score,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "# 1) Prepare features and labels\n",
    "# selected_features = [\n",
    "#     'duration',\n",
    "#     'lat_mean', 'lon_mean',\n",
    "#     'lat_std',  'lon_std',\n",
    "#     'lat_median','lon_median',\n",
    "#     'lat_max',  'lon_max',\n",
    "#     'lat_min',  'lon_min',\n",
    "#     'start_lat','start_lon',\n",
    "#     'end_lat',  'end_lon',\n",
    "#     'lat_range','lon_range',\n",
    "#     'speed_mean','speed_max','speed_std',\n",
    "#     # 'wspd','gst','wvht','atmp'\n",
    "# ]\n",
    "# X = features[selected_features]\n",
    "\n",
    "X = features_df\n",
    "# y = all_df['Label']\n",
    "y = segmented_df['Label']\n",
    "\n",
    "# 2) Split into train+val (80 %) and test (20 %)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y,\n",
    "    stratify=y,\n",
    "    test_size=0.20,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 3) Split train+val into train (60 %) and val (20 %)\n",
    "#    Since X_temp is 80 %, using test_size=0.25 on it gives 0.25*0.8 = 0.20 overall\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    stratify=y_temp,\n",
    "    test_size=0.25,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 4) Define your classifiers\n",
    "clfs = {\n",
    "    'RandomForest': RandomForestClassifier(\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_estimators=100\n",
    "    ),\n",
    "}\n",
    "\n",
    "# 5) Train, tune threshold on validation, and report\n",
    "best_thresholds = {}\n",
    "for name, clf in clfs.items():\n",
    "    # Train\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Get validation scores\n",
    "    val_scores = clf.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    # Compute precision–recall curve\n",
    "    precision, recall, thresholds = precision_recall_curve(y_val, val_scores)\n",
    "    \n",
    "    # Compute F1 for each threshold (exclude last point)\n",
    "    f1_scores = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1] + 1e-6)\n",
    "    \n",
    "    # Pick best\n",
    "    best_idx = np.argmax(f1_scores)\n",
    "    best_threshold = thresholds[best_idx]\n",
    "    best_f1_val = f1_scores[best_idx]\n",
    "    best_thresholds[name] = best_threshold\n",
    "    \n",
    "    print(f\"{name} → best validation threshold = {best_threshold:.4f} (F1 = {best_f1_val:.4f})\")\n",
    "\n",
    "# 6) Evaluate on the test set using the tuned thresholds\n",
    "for name, clf in clfs.items():\n",
    "    thresh = best_thresholds[name]\n",
    "    # thresh = 0.5\n",
    "    test_scores = clf.predict_proba(X_test)[:, 1]\n",
    "    y_test_pred = (test_scores >= thresh).astype(int)\n",
    "    \n",
    "    print(f\"\\n{name} test set @ threshold {thresh:.4f}:\")\n",
    "    print(classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = clf.feature_importances_\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "result = permutation_importance(clf, X_test, y_test, n_repeats=30, random_state=42, n_jobs=-1)\n",
    "\n",
    "perm_importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance_mean': result.importances_mean,\n",
    "    'Importance_std': result.importances_std\n",
    "}).sort_values(by='Importance_mean', ascending=False)\n",
    "\n",
    "print(perm_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# For SHAP, take your trained classifier\n",
    "# Let's assume you trained `clf` already\n",
    "\n",
    "# Create SHAP explainer for tree-based model\n",
    "explainer = shap.TreeExplainer(clf)\n",
    "\n",
    "# Compute SHAP values on a sample of your data (to save time, use validation or small sample)\n",
    "# For full explanation you can use X_train or X_val\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For binary classification, shap_values[1] corresponds to class 1\n",
    "shap.summary_plot(shap_values[:,:,1], X_test, plot_type=\"bar\", max_display=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampled Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from scipy.interpolate import interp1d\n",
    "\n",
    "# def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "#     R = 6371000  # Earth radius in meters\n",
    "#     lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "#     dlat = lat2 - lat1\n",
    "#     dlon = lon2 - lon1\n",
    "#     a = np.sin(dlat / 2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0)**2\n",
    "#     c = 2 * np.arcsin(np.sqrt(a))\n",
    "#     return R * c  # in meters\n",
    "\n",
    "# def compute_motion_features(lat, lon, elapsed):\n",
    "#     lat = np.array(lat)\n",
    "#     lon = np.array(lon)\n",
    "#     elapsed = np.array(elapsed)\n",
    "#     time_diff = np.diff(elapsed, prepend=elapsed[0]) + 1e-10  # avoid division by zero\n",
    "    \n",
    "\n",
    "#     distance = haversine_distance(lat[:-1], lon[:-1], lat[1:], lon[1:])\n",
    "#     distance = np.insert(distance, 0, 0.0)\n",
    "    \n",
    "#     speed = distance / time_diff\n",
    "    \n",
    "#     delta_speed = np.diff(speed, prepend=speed[0])\n",
    "#     acceleration = delta_speed / time_diff\n",
    "    \n",
    "#     return distance, speed, acceleration\n",
    "\n",
    "# def resample_fixed_length(row, n_points=100, interval=71):\n",
    "#     elapsed = np.array(row['elapsed_s'])\n",
    "#     lat    = np.array(row['LAT'])\n",
    "#     lon    = np.array(row['LON'])\n",
    "#     label  = row['Label']\n",
    "\n",
    "#     # Step 1: Compute motion features\n",
    "#     distance, speed, acceleration = compute_motion_features(lat, lon, elapsed)\n",
    "\n",
    "#     # Step 2: Create interpolation targets\n",
    "#     t0 = elapsed[0]\n",
    "#     targets = t0 + np.arange(n_points) * interval\n",
    "\n",
    "#     # Step 3: Interpolators with boundary fill\n",
    "#     interp_opts = dict(kind='linear', bounds_error=False)\n",
    "#     lat_i  = interp1d(elapsed, lat, fill_value=(lat[0], lat[-1]), **interp_opts)\n",
    "#     lon_i  = interp1d(elapsed, lon, fill_value=(lon[0], lon[-1]), **interp_opts)\n",
    "#     dist_i = interp1d(elapsed, distance, fill_value=(distance[0], distance[-1]), **interp_opts)\n",
    "#     spd_i  = interp1d(elapsed, speed, fill_value=(speed[0], speed[-1]), **interp_opts)\n",
    "#     acc_i  = interp1d(elapsed, acceleration, fill_value=(acceleration[0], acceleration[-1]), **interp_opts)\n",
    "\n",
    "#     # Step 4: Apply interpolation\n",
    "#     targets = targets.tolist()\n",
    "#     return pd.Series({\n",
    "#         'elapsed_s': targets,\n",
    "#         'LAT': lat_i(targets).tolist(),\n",
    "#         'LON': lon_i(targets).tolist(),\n",
    "#         'distance': dist_i(targets).tolist(),\n",
    "#         'speed': spd_i(targets).tolist(),\n",
    "#         'acceleration': acc_i(targets).tolist(),\n",
    "#         'Label': label\n",
    "#     })\n",
    "\n",
    "\n",
    "# resampled_df = segmented_df.apply(resample_fixed_length, axis=1)\n",
    "\n",
    "# resampled_df.to_pickle('../AIS_preprocessed_data/resampled_trajectories_2019.pkl')\n",
    "# # Load the resampled DataFrame\n",
    "# resampled_df = pd.read_pickle('../AIS_preprocessed_data/resampled_trajectories_2019.pkl')\n",
    "# resampled_df.to_pickle('../AIS_preprocessed_data/resampled_trajectories_2019.pkl')\n",
    "# # Load the resampled DataFrame\n",
    "resampled_df = pd.read_pickle('../AIS_preprocessed_data/resampled_trajectories_2019.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elapsed_s</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>distance</th>\n",
       "      <th>speed</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 71, 142, 213, 284, 355, 426, 497, 568, 639...</td>\n",
       "      <td>[30.4289, 30.427711304347827, 30.4266933333333...</td>\n",
       "      <td>[-87.99302, -87.99256028985508, -87.9918661111...</td>\n",
       "      <td>[0.0, 135.48465254564982, 127.9235195796064, 1...</td>\n",
       "      <td>[0.0, 1.9635456890645429, 1.8496829442018017, ...</td>\n",
       "      <td>[0.0, 0.027630967207069198, -0.001604087755998...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 71, 142, 213, 284, 355, 426, 497, 568, 639...</td>\n",
       "      <td>[29.01648, 29.016659746835444, 29.016641772151...</td>\n",
       "      <td>[-91.83069, -91.83176632911392, -91.8329256962...</td>\n",
       "      <td>[0.0, 105.25625309708458, 123.64340449440272, ...</td>\n",
       "      <td>[0.0, 1.5010762230819907, 1.5802477978313674, ...</td>\n",
       "      <td>[0.0, 0.021170890535155733, 0.0029149719037867...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 71, 142, 213, 284, 355, 426, 497, 568, 639...</td>\n",
       "      <td>[29.38964, 29.385496363636364, 29.381288333333...</td>\n",
       "      <td>[-91.36791, -91.37174181818182, -91.3756183333...</td>\n",
       "      <td>[0.0, 542.4017027357, 559.003347600951, 648.09...</td>\n",
       "      <td>[0.0, 8.333145458834952, 8.469747690910667, 9....</td>\n",
       "      <td>[0.0, 0.11653427000190719, 0.00221293589292710...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 71, 142, 213, 284, 355, 426, 497, 568, 639...</td>\n",
       "      <td>[28.82299, 28.823143833333333, 28.823292541436...</td>\n",
       "      <td>[-89.33299, -89.33333316666666, -89.3336587292...</td>\n",
       "      <td>[0.0, 37.55305125505398, 65.60898759777186, 72...</td>\n",
       "      <td>[0.0, 0.3129420937918557, 0.5190679504016775, ...</td>\n",
       "      <td>[0.0, 0.0026078507815966243, 0.003817490167018...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 71, 142, 213, 284, 355, 426, 497, 568, 639...</td>\n",
       "      <td>[30.18058, 30.17844014492754, 30.1763174285714...</td>\n",
       "      <td>[-88.56405, -88.56749898550724, -88.5709795714...</td>\n",
       "      <td>[0.0, 402.2454557039614, 398.176562511638, 409...</td>\n",
       "      <td>[0.0, 5.747556472194515, 5.767013801201017, 5....</td>\n",
       "      <td>[0.0, 0.08091806311282652, 0.00027507094092510...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301701</th>\n",
       "      <td>[0, 71, 142, 213, 284, 355, 426, 497, 568, 639...</td>\n",
       "      <td>[28.91509, 28.91225, 28.909456923076924, 28.90...</td>\n",
       "      <td>[-89.42226, -89.42481950617284, -89.4274877622...</td>\n",
       "      <td>[0.0, 402.23199527292843, 611.3733122390581, 7...</td>\n",
       "      <td>[0.0, 4.965827102128787, 5.683821243452402, 5....</td>\n",
       "      <td>[0.0, 0.06130650743361305, 0.04023610119046052...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301702</th>\n",
       "      <td>[0, 71, 142, 213, 284, 355, 426, 497, 568, 639...</td>\n",
       "      <td>[28.91911, 28.915883442622953, 28.912868550724...</td>\n",
       "      <td>[-89.4197, -89.42206229508196, -89.42432840579...</td>\n",
       "      <td>[0.0, 412.53084538144964, 392.95653179608195, ...</td>\n",
       "      <td>[0.0, 6.0003290597827315, 5.677408013015349, 5...</td>\n",
       "      <td>[0.0, 0.08408492367594013, -0.0050411706004467...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301703</th>\n",
       "      <td>[0, 71, 142, 213, 284, 355, 426, 497, 568, 639...</td>\n",
       "      <td>[29.07654, 29.0742964, 29.07187769230769, 29.0...</td>\n",
       "      <td>[-90.22863, -90.228985, -90.22936907692308, -9...</td>\n",
       "      <td>[0.0, 251.8511100370956, 408.7752116460868, 50...</td>\n",
       "      <td>[0.0, 2.5185111003684373, 3.698543323599662, 3...</td>\n",
       "      <td>[0.0, 0.025185111003659187, 0.0251759959665140...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301704</th>\n",
       "      <td>[0, 71, 142, 213, 284, 355, 426, 497, 568, 639...</td>\n",
       "      <td>[30.64235, 30.638184666666668, 30.633730281690...</td>\n",
       "      <td>[-88.03225, -88.03232888888888, -88.0323573239...</td>\n",
       "      <td>[0.0, 463.2254235001607, 528.4949847700653, 54...</td>\n",
       "      <td>[0.0, 5.1469491499960665, 6.976367980696347, 7...</td>\n",
       "      <td>[0.0, 0.05718832388878164, 0.02576646240419878...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301705</th>\n",
       "      <td>[0, 71, 142, 213, 284, 355, 426, 497, 568, 639...</td>\n",
       "      <td>[28.91971, 28.916114555555556, 28.912888, 28.9...</td>\n",
       "      <td>[-89.41942, -89.42207883333333, -89.424836, -8...</td>\n",
       "      <td>[0.0, 473.6455247192075, 736.3224070711121, 99...</td>\n",
       "      <td>[0.0, 6.71127310592543, 6.552301160000007, 6.3...</td>\n",
       "      <td>[0.0, 0.0953620588477423, 0.05664877323816109,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>301706 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                elapsed_s  \\\n",
       "0       [0, 71, 142, 213, 284, 355, 426, 497, 568, 639...   \n",
       "1       [0, 71, 142, 213, 284, 355, 426, 497, 568, 639...   \n",
       "2       [0, 71, 142, 213, 284, 355, 426, 497, 568, 639...   \n",
       "3       [0, 71, 142, 213, 284, 355, 426, 497, 568, 639...   \n",
       "4       [0, 71, 142, 213, 284, 355, 426, 497, 568, 639...   \n",
       "...                                                   ...   \n",
       "301701  [0, 71, 142, 213, 284, 355, 426, 497, 568, 639...   \n",
       "301702  [0, 71, 142, 213, 284, 355, 426, 497, 568, 639...   \n",
       "301703  [0, 71, 142, 213, 284, 355, 426, 497, 568, 639...   \n",
       "301704  [0, 71, 142, 213, 284, 355, 426, 497, 568, 639...   \n",
       "301705  [0, 71, 142, 213, 284, 355, 426, 497, 568, 639...   \n",
       "\n",
       "                                                      LAT  \\\n",
       "0       [30.4289, 30.427711304347827, 30.4266933333333...   \n",
       "1       [29.01648, 29.016659746835444, 29.016641772151...   \n",
       "2       [29.38964, 29.385496363636364, 29.381288333333...   \n",
       "3       [28.82299, 28.823143833333333, 28.823292541436...   \n",
       "4       [30.18058, 30.17844014492754, 30.1763174285714...   \n",
       "...                                                   ...   \n",
       "301701  [28.91509, 28.91225, 28.909456923076924, 28.90...   \n",
       "301702  [28.91911, 28.915883442622953, 28.912868550724...   \n",
       "301703  [29.07654, 29.0742964, 29.07187769230769, 29.0...   \n",
       "301704  [30.64235, 30.638184666666668, 30.633730281690...   \n",
       "301705  [28.91971, 28.916114555555556, 28.912888, 28.9...   \n",
       "\n",
       "                                                      LON  \\\n",
       "0       [-87.99302, -87.99256028985508, -87.9918661111...   \n",
       "1       [-91.83069, -91.83176632911392, -91.8329256962...   \n",
       "2       [-91.36791, -91.37174181818182, -91.3756183333...   \n",
       "3       [-89.33299, -89.33333316666666, -89.3336587292...   \n",
       "4       [-88.56405, -88.56749898550724, -88.5709795714...   \n",
       "...                                                   ...   \n",
       "301701  [-89.42226, -89.42481950617284, -89.4274877622...   \n",
       "301702  [-89.4197, -89.42206229508196, -89.42432840579...   \n",
       "301703  [-90.22863, -90.228985, -90.22936907692308, -9...   \n",
       "301704  [-88.03225, -88.03232888888888, -88.0323573239...   \n",
       "301705  [-89.41942, -89.42207883333333, -89.424836, -8...   \n",
       "\n",
       "                                                 distance  \\\n",
       "0       [0.0, 135.48465254564982, 127.9235195796064, 1...   \n",
       "1       [0.0, 105.25625309708458, 123.64340449440272, ...   \n",
       "2       [0.0, 542.4017027357, 559.003347600951, 648.09...   \n",
       "3       [0.0, 37.55305125505398, 65.60898759777186, 72...   \n",
       "4       [0.0, 402.2454557039614, 398.176562511638, 409...   \n",
       "...                                                   ...   \n",
       "301701  [0.0, 402.23199527292843, 611.3733122390581, 7...   \n",
       "301702  [0.0, 412.53084538144964, 392.95653179608195, ...   \n",
       "301703  [0.0, 251.8511100370956, 408.7752116460868, 50...   \n",
       "301704  [0.0, 463.2254235001607, 528.4949847700653, 54...   \n",
       "301705  [0.0, 473.6455247192075, 736.3224070711121, 99...   \n",
       "\n",
       "                                                    speed  \\\n",
       "0       [0.0, 1.9635456890645429, 1.8496829442018017, ...   \n",
       "1       [0.0, 1.5010762230819907, 1.5802477978313674, ...   \n",
       "2       [0.0, 8.333145458834952, 8.469747690910667, 9....   \n",
       "3       [0.0, 0.3129420937918557, 0.5190679504016775, ...   \n",
       "4       [0.0, 5.747556472194515, 5.767013801201017, 5....   \n",
       "...                                                   ...   \n",
       "301701  [0.0, 4.965827102128787, 5.683821243452402, 5....   \n",
       "301702  [0.0, 6.0003290597827315, 5.677408013015349, 5...   \n",
       "301703  [0.0, 2.5185111003684373, 3.698543323599662, 3...   \n",
       "301704  [0.0, 5.1469491499960665, 6.976367980696347, 7...   \n",
       "301705  [0.0, 6.71127310592543, 6.552301160000007, 6.3...   \n",
       "\n",
       "                                             acceleration  Label  \n",
       "0       [0.0, 0.027630967207069198, -0.001604087755998...      0  \n",
       "1       [0.0, 0.021170890535155733, 0.0029149719037867...      0  \n",
       "2       [0.0, 0.11653427000190719, 0.00221293589292710...      0  \n",
       "3       [0.0, 0.0026078507815966243, 0.003817490167018...      0  \n",
       "4       [0.0, 0.08091806311282652, 0.00027507094092510...      0  \n",
       "...                                                   ...    ...  \n",
       "301701  [0.0, 0.06130650743361305, 0.04023610119046052...      0  \n",
       "301702  [0.0, 0.08408492367594013, -0.0050411706004467...      0  \n",
       "301703  [0.0, 0.025185111003659187, 0.0251759959665140...      0  \n",
       "301704  [0.0, 0.05718832388878164, 0.02576646240419878...      0  \n",
       "301705  [0.0, 0.0953620588477423, 0.05664877323816109,...      0  \n",
       "\n",
       "[301706 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_array = np.stack(resampled_df['LAT'].values)    # shape: (num_instances, 156)\n",
    "lon_array = np.stack(resampled_df['LON'].values)    # shape: (num_instances, 156)\n",
    "speed_array = np.stack(resampled_df['speed'].values)  # shape: (num_instances, 156)\n",
    "acceleration_array = np.stack(resampled_df['acceleration'].values)  # shape: (num_instances, 156)\n",
    "\n",
    "\n",
    "# Now stack lat, lon, and speed\n",
    "X = np.stack([lat_array, lon_array, speed_array,acceleration_array], axis=1)  # shape: (num_instances, 3, 156)\n",
    "\n",
    "y = resampled_df['Label'].values  # shape: (num_instances,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(301706, 4, 100)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First split into train and temp (temp will be split into val/test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Now split temp into validation and test\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, stratify=y_temp, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(241364, 4, 100)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before creating TensorDataset:\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_val   = X_val.astype(np.float32)\n",
    "X_test  = X_test.astype(np.float32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute sampling weights (inverse of class frequency)\n",
    "class_sample_count = np.array([(y_train == 0).sum(), (y_train == 1).sum()])\n",
    "weights = 1. / class_sample_count\n",
    "sample_weights = weights[y_train.astype(int)]\n",
    "sampler = WeightedRandomSampler(sample_weights, len(sample_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super().__init__()\n",
    "        # First Conv1d layer\n",
    "        self.conv1 = nn.Conv1d(input_channels, 16, kernel_size=5, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)          # halve sequence length\n",
    "        \n",
    "        # Second Conv1d layer\n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=5, padding=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2)          # halve again\n",
    "        \n",
    "        # Global average pooling + classifier\n",
    "        self.global_avg = nn.AdaptiveAvgPool1d(1)         # output shape: (batch, 32, 1)\n",
    "        self.classifier = nn.Linear(32, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (batch, channels, seq_len)\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.pool1(out)      # now shape (batch, 16, seq_len/2)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.pool2(out)      # now shape (batch, 32, seq_len/4)\n",
    "        \n",
    "        out = self.global_avg(out) # (batch, 32, 1)\n",
    "        out = out.squeeze(2)       # (batch, 32)\n",
    "        return self.classifier(out)  # (batch, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionBlock1D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        assert out_channels % 4 == 0, \"out_channels must be divisible by 4\"\n",
    "        branch_channels = out_channels // 4\n",
    "\n",
    "        self.branch1 = nn.Conv1d(in_channels, branch_channels, kernel_size=1)\n",
    "\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, branch_channels, kernel_size=1),\n",
    "            nn.Conv1d(branch_channels, branch_channels, kernel_size=3, padding=1)\n",
    "        )\n",
    "\n",
    "        self.branch5 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, branch_channels, kernel_size=1),\n",
    "            nn.Conv1d(branch_channels, branch_channels, kernel_size=5, padding=2)\n",
    "        )\n",
    "\n",
    "        self.pool_branch = nn.Sequential(\n",
    "            nn.MaxPool1d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv1d(in_channels, branch_channels, kernel_size=1)\n",
    "        )\n",
    "\n",
    "        self.batchnorm = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        b1 = self.branch1(x)\n",
    "        b3 = self.branch3(x)\n",
    "        b5 = self.branch5(x)\n",
    "        bp = self.pool_branch(x)\n",
    "        out = torch.cat([b1, b3, b5, bp], dim=1)\n",
    "        return self.relu(self.batchnorm(out))\n",
    "    \n",
    "\n",
    "class InceptionCNN1D(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes, dropout_rate=0.3):\n",
    "        super().__init__()\n",
    "        self.inception1 = InceptionBlock1D(input_channels, 64)\n",
    "        self.inception2 = InceptionBlock1D(64, 128)\n",
    "        self.inception3 = InceptionBlock1D(128, 128)\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.classifier = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, input_channels, seq_len)\n",
    "        x = self.inception1(x)\n",
    "        x = self.inception2(x)\n",
    "        x = self.inception3(x)\n",
    "        x = self.pool(x).squeeze(-1)  # (batch, 128)\n",
    "        x = self.dropout(x)\n",
    "        return self.classifier(x)     # (batch, num_classes)\n",
    "# Create the model instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# cast to float64 so that sums/squares don't overflow\n",
    "X_train_f = X_train.astype(np.float64)\n",
    "X_val_f   = X_val.astype(np.float64)\n",
    "X_test_f  = X_test.astype(np.float64)\n",
    "\n",
    "# compute means in float64\n",
    "means = np.mean(X_train_f, axis=(0, 2), dtype=np.float64)   # shape (V,)\n",
    "# compute variance using float64 then sqrt\n",
    "vars_ = np.mean((X_train_f - means.reshape(1, -1, 1))**2,\n",
    "                axis=(0, 2), dtype=np.float64)\n",
    "stds = np.sqrt(vars_)\n",
    "\n",
    "# guard against zeros\n",
    "stds[stds == 0] = 1.0\n",
    "\n",
    "# reshape for broadcasting\n",
    "means = means.reshape(1, -1, 1)\n",
    "stds  = stds.reshape(1, -1, 1)\n",
    "\n",
    "# normalize\n",
    "X_train_norm = (X_train_f - means) / stds\n",
    "X_val_norm   = (X_val_f   - means) / stds\n",
    "X_test_norm  = (X_test_f  - means) / stds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When converting to torch tensors:\n",
    "train_ds = TensorDataset(torch.tensor(X_train_norm, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n",
    "val_ds   = TensorDataset(torch.tensor(X_val_norm, dtype=torch.float32), torch.tensor(y_val, dtype=torch.float32))\n",
    "test_ds  = TensorDataset(torch.tensor(X_test_norm, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32))\n",
    "\n",
    "batch_size = 64\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, sampler=sampler)\n",
    "val_dl   = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "test_dl  = DataLoader(test_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Multiclass F1: 0.452\n",
      "Epoch 2, Multiclass F1: 0.461\n",
      "Epoch 3, Multiclass F1: 0.464\n",
      "Epoch 4, Multiclass F1: 0.478\n",
      "Epoch 5, Multiclass F1: 0.477\n",
      "Epoch 6, Multiclass F1: 0.469\n",
      "Epoch 7, Multiclass F1: 0.462\n",
      "Epoch 8, Multiclass F1: 0.496\n",
      "Epoch 9, Multiclass F1: 0.469\n",
      "Epoch 10, Multiclass F1: 0.484\n",
      "Epoch 11, Multiclass F1: 0.481\n",
      "Epoch 12, Multiclass F1: 0.474\n",
      "Epoch 13, Multiclass F1: 0.492\n",
      "Epoch 14, Multiclass F1: 0.489\n",
      "Epoch 15, Multiclass F1: 0.471\n",
      "Epoch 16, Multiclass F1: 0.475\n",
      "Epoch 17, Multiclass F1: 0.465\n",
      "Epoch 18, Multiclass F1: 0.483\n",
      "Epoch 19, Multiclass F1: 0.483\n",
      "Epoch 20, Multiclass F1: 0.470\n",
      "Epoch 21, Multiclass F1: 0.494\n",
      "Epoch 22, Multiclass F1: 0.496\n",
      "Epoch 23, Multiclass F1: 0.476\n",
      "Epoch 24, Multiclass F1: 0.480\n",
      "Epoch 25, Multiclass F1: 0.483\n",
      "Epoch 26, Multiclass F1: 0.489\n",
      "Epoch 27, Multiclass F1: 0.487\n",
      "Epoch 28, Multiclass F1: 0.479\n",
      "Epoch 29, Multiclass F1: 0.477\n",
      "Epoch 30, Multiclass F1: 0.483\n",
      "Epoch 31, Multiclass F1: 0.491\n",
      "Epoch 32, Multiclass F1: 0.482\n",
      "Epoch 33, Multiclass F1: 0.486\n",
      "Epoch 34, Multiclass F1: 0.487\n",
      "Epoch 35, Multiclass F1: 0.501\n",
      "Epoch 36, Multiclass F1: 0.485\n",
      "Epoch 37, Multiclass F1: 0.485\n",
      "Epoch 38, Multiclass F1: 0.470\n",
      "Epoch 39, Multiclass F1: 0.490\n",
      "Epoch 40, Multiclass F1: 0.495\n",
      "Epoch 41, Multiclass F1: 0.475\n",
      "Epoch 42, Multiclass F1: 0.492\n",
      "Epoch 43, Multiclass F1: 0.471\n",
      "Epoch 44, Multiclass F1: 0.493\n",
      "Epoch 45, Multiclass F1: 0.503\n",
      "Epoch 46, Multiclass F1: 0.489\n",
      "Epoch 47, Multiclass F1: 0.482\n",
      "Epoch 48, Multiclass F1: 0.488\n",
      "Epoch 49, Multiclass F1: 0.495\n",
      "Epoch 50, Multiclass F1: 0.497\n",
      "Epoch 51, Multiclass F1: 0.477\n",
      "Epoch 52, Multiclass F1: 0.499\n",
      "Epoch 53, Multiclass F1: 0.491\n",
      "Epoch 54, Multiclass F1: 0.486\n",
      "Epoch 55, Multiclass F1: 0.496\n",
      "Epoch 56, Multiclass F1: 0.498\n",
      "Epoch 57, Multiclass F1: 0.498\n",
      "Epoch 58, Multiclass F1: 0.497\n",
      "Epoch 59, Multiclass F1: 0.506\n",
      "Epoch 60, Multiclass F1: 0.501\n",
      "Epoch 61, Multiclass F1: 0.486\n",
      "Epoch 62, Multiclass F1: 0.503\n",
      "Epoch 63, Multiclass F1: 0.511\n",
      "Epoch 64, Multiclass F1: 0.505\n",
      "Epoch 65, Multiclass F1: 0.503\n",
      "Epoch 66, Multiclass F1: 0.486\n",
      "Epoch 67, Multiclass F1: 0.496\n",
      "Epoch 68, Multiclass F1: 0.500\n",
      "Epoch 69, Multiclass F1: 0.502\n",
      "Epoch 70, Multiclass F1: 0.509\n",
      "Epoch 71, Multiclass F1: 0.513\n",
      "Epoch 72, Multiclass F1: 0.504\n",
      "Epoch 73, Multiclass F1: 0.487\n",
      "Epoch 74, Multiclass F1: 0.492\n",
      "Epoch 75, Multiclass F1: 0.494\n",
      "Epoch 76, Multiclass F1: 0.499\n",
      "Epoch 77, Multiclass F1: 0.497\n",
      "Epoch 78, Multiclass F1: 0.498\n",
      "Epoch 79, Multiclass F1: 0.494\n",
      "Epoch 80, Multiclass F1: 0.497\n",
      "Epoch 81, Multiclass F1: 0.509\n",
      "Epoch 82, Multiclass F1: 0.495\n",
      "Epoch 83, Multiclass F1: 0.494\n",
      "Epoch 84, Multiclass F1: 0.510\n",
      "Epoch 85, Multiclass F1: 0.507\n",
      "Epoch 86, Multiclass F1: 0.513\n",
      "Epoch 87, Multiclass F1: 0.524\n",
      "Epoch 88, Multiclass F1: 0.498\n",
      "Epoch 89, Multiclass F1: 0.512\n",
      "Epoch 90, Multiclass F1: 0.509\n",
      "Epoch 91, Multiclass F1: 0.510\n",
      "Epoch 92, Multiclass F1: 0.508\n",
      "Epoch 93, Multiclass F1: 0.513\n",
      "Epoch 94, Multiclass F1: 0.517\n",
      "Epoch 95, Multiclass F1: 0.505\n",
      "Epoch 96, Multiclass F1: 0.504\n",
      "Epoch 97, Multiclass F1: 0.513\n",
      "Epoch 98, Multiclass F1: 0.506\n",
      "Epoch 99, Multiclass F1: 0.520\n",
      "Epoch 100, Multiclass F1: 0.522\n",
      "Epoch 101, Multiclass F1: 0.507\n",
      "Epoch 102, Multiclass F1: 0.514\n",
      "Epoch 103, Multiclass F1: 0.511\n",
      "Epoch 104, Multiclass F1: 0.513\n",
      "Epoch 105, Multiclass F1: 0.512\n",
      "Epoch 106, Multiclass F1: 0.519\n",
      "Epoch 107, Multiclass F1: 0.515\n",
      "Epoch 108, Multiclass F1: 0.514\n",
      "Epoch 109, Multiclass F1: 0.528\n",
      "Epoch 110, Multiclass F1: 0.505\n",
      "Epoch 111, Multiclass F1: 0.532\n",
      "Epoch 112, Multiclass F1: 0.522\n",
      "Epoch 113, Multiclass F1: 0.523\n",
      "Epoch 114, Multiclass F1: 0.511\n",
      "Epoch 115, Multiclass F1: 0.535\n",
      "Epoch 116, Multiclass F1: 0.516\n",
      "Epoch 117, Multiclass F1: 0.521\n",
      "Epoch 118, Multiclass F1: 0.521\n",
      "Epoch 119, Multiclass F1: 0.506\n",
      "Epoch 120, Multiclass F1: 0.529\n",
      "Epoch 121, Multiclass F1: 0.518\n",
      "Epoch 122, Multiclass F1: 0.522\n",
      "Epoch 123, Multiclass F1: 0.527\n",
      "Epoch 124, Multiclass F1: 0.529\n",
      "Epoch 125, Multiclass F1: 0.527\n",
      "Epoch 126, Multiclass F1: 0.522\n",
      "Epoch 127, Multiclass F1: 0.518\n",
      "Epoch 128, Multiclass F1: 0.526\n",
      "Epoch 129, Multiclass F1: 0.536\n",
      "Epoch 130, Multiclass F1: 0.522\n",
      "Epoch 131, Multiclass F1: 0.506\n",
      "Epoch 132, Multiclass F1: 0.520\n",
      "Epoch 133, Multiclass F1: 0.529\n",
      "Epoch 134, Multiclass F1: 0.526\n",
      "Epoch 135, Multiclass F1: 0.529\n",
      "Epoch 136, Multiclass F1: 0.516\n",
      "Epoch 137, Multiclass F1: 0.518\n",
      "Epoch 138, Multiclass F1: 0.528\n",
      "Epoch 139, Multiclass F1: 0.505\n",
      "Epoch 140, Multiclass F1: 0.511\n",
      "Epoch 141, Multiclass F1: 0.515\n",
      "Epoch 142, Multiclass F1: 0.515\n",
      "Epoch 143, Multiclass F1: 0.521\n",
      "Epoch 144, Multiclass F1: 0.524\n",
      "Epoch 145, Multiclass F1: 0.518\n",
      "Epoch 146, Multiclass F1: 0.533\n",
      "Epoch 147, Multiclass F1: 0.535\n",
      "Epoch 148, Multiclass F1: 0.511\n",
      "Epoch 149, Multiclass F1: 0.521\n",
      "Epoch 150, Multiclass F1: 0.520\n",
      "Epoch 151, Multiclass F1: 0.519\n",
      "Epoch 152, Multiclass F1: 0.519\n",
      "Epoch 153, Multiclass F1: 0.504\n",
      "Epoch 154, Multiclass F1: 0.525\n",
      "Epoch 155, Multiclass F1: 0.531\n",
      "Epoch 156, Multiclass F1: 0.529\n",
      "Epoch 157, Multiclass F1: 0.525\n",
      "Epoch 158, Multiclass F1: 0.530\n",
      "Epoch 159, Multiclass F1: 0.522\n",
      "Epoch 160, Multiclass F1: 0.533\n",
      "Epoch 161, Multiclass F1: 0.532\n",
      "Epoch 162, Multiclass F1: 0.524\n",
      "Epoch 163, Multiclass F1: 0.514\n",
      "Epoch 164, Multiclass F1: 0.538\n",
      "Epoch 165, Multiclass F1: 0.523\n",
      "Epoch 166, Multiclass F1: 0.504\n",
      "Epoch 167, Multiclass F1: 0.515\n",
      "Epoch 168, Multiclass F1: 0.534\n",
      "Epoch 169, Multiclass F1: 0.526\n",
      "Epoch 170, Multiclass F1: 0.498\n",
      "Epoch 171, Multiclass F1: 0.526\n",
      "Epoch 172, Multiclass F1: 0.530\n",
      "Epoch 173, Multiclass F1: 0.525\n",
      "Epoch 174, Multiclass F1: 0.518\n",
      "Epoch 175, Multiclass F1: 0.533\n",
      "Epoch 176, Multiclass F1: 0.526\n",
      "Epoch 177, Multiclass F1: 0.522\n",
      "Epoch 178, Multiclass F1: 0.531\n",
      "Epoch 179, Multiclass F1: 0.512\n",
      "Epoch 180, Multiclass F1: 0.514\n",
      "Epoch 181, Multiclass F1: 0.519\n",
      "Epoch 182, Multiclass F1: 0.520\n",
      "Epoch 183, Multiclass F1: 0.505\n",
      "Epoch 184, Multiclass F1: 0.518\n",
      "Epoch 185, Multiclass F1: 0.536\n",
      "Epoch 186, Multiclass F1: 0.518\n",
      "Epoch 187, Multiclass F1: 0.536\n",
      "Epoch 188, Multiclass F1: 0.529\n",
      "Epoch 189, Multiclass F1: 0.526\n",
      "Epoch 190, Multiclass F1: 0.494\n",
      "Epoch 191, Multiclass F1: 0.520\n",
      "Epoch 192, Multiclass F1: 0.525\n",
      "Epoch 193, Multiclass F1: 0.511\n",
      "Epoch 194, Multiclass F1: 0.516\n",
      "Epoch 195, Multiclass F1: 0.526\n",
      "Epoch 196, Multiclass F1: 0.528\n",
      "Epoch 197, Multiclass F1: 0.530\n",
      "Epoch 198, Multiclass F1: 0.510\n",
      "Epoch 199, Multiclass F1: 0.534\n",
      "Epoch 200, Multiclass F1: 0.538\n",
      "Epoch 201, Multiclass F1: 0.530\n",
      "Epoch 202, Multiclass F1: 0.535\n",
      "Epoch 203, Multiclass F1: 0.532\n",
      "Epoch 204, Multiclass F1: 0.537\n",
      "Epoch 205, Multiclass F1: 0.544\n",
      "Epoch 206, Multiclass F1: 0.534\n",
      "Epoch 207, Multiclass F1: 0.528\n",
      "Epoch 208, Multiclass F1: 0.546\n",
      "Epoch 209, Multiclass F1: 0.525\n",
      "Epoch 210, Multiclass F1: 0.533\n",
      "Epoch 211, Multiclass F1: 0.527\n",
      "Epoch 212, Multiclass F1: 0.528\n",
      "Epoch 213, Multiclass F1: 0.539\n",
      "Epoch 214, Multiclass F1: 0.531\n",
      "Epoch 215, Multiclass F1: 0.530\n",
      "Epoch 216, Multiclass F1: 0.526\n",
      "Epoch 217, Multiclass F1: 0.525\n",
      "Epoch 218, Multiclass F1: 0.531\n",
      "Epoch 219, Multiclass F1: 0.539\n",
      "Epoch 220, Multiclass F1: 0.531\n",
      "Epoch 221, Multiclass F1: 0.527\n",
      "Epoch 222, Multiclass F1: 0.518\n",
      "Epoch 223, Multiclass F1: 0.546\n",
      "Epoch 224, Multiclass F1: 0.531\n",
      "Epoch 225, Multiclass F1: 0.532\n",
      "Epoch 226, Multiclass F1: 0.539\n",
      "Epoch 227, Multiclass F1: 0.536\n",
      "Epoch 228, Multiclass F1: 0.507\n",
      "Epoch 229, Multiclass F1: 0.525\n",
      "Epoch 230, Multiclass F1: 0.531\n",
      "Epoch 231, Multiclass F1: 0.520\n",
      "Epoch 232, Multiclass F1: 0.535\n",
      "Epoch 233, Multiclass F1: 0.524\n",
      "Epoch 234, Multiclass F1: 0.526\n",
      "Epoch 235, Multiclass F1: 0.527\n",
      "Epoch 236, Multiclass F1: 0.534\n",
      "Epoch 237, Multiclass F1: 0.506\n",
      "Epoch 238, Multiclass F1: 0.539\n",
      "Epoch 239, Multiclass F1: 0.528\n",
      "Epoch 240, Multiclass F1: 0.540\n",
      "Epoch 241, Multiclass F1: 0.528\n",
      "Epoch 242, Multiclass F1: 0.535\n",
      "Epoch 243, Multiclass F1: 0.537\n",
      "Epoch 244, Multiclass F1: 0.514\n",
      "Epoch 245, Multiclass F1: 0.550\n",
      "Epoch 246, Multiclass F1: 0.534\n",
      "Epoch 247, Multiclass F1: 0.515\n",
      "Epoch 248, Multiclass F1: 0.530\n",
      "Epoch 249, Multiclass F1: 0.544\n",
      "Epoch 250, Multiclass F1: 0.524\n",
      "Epoch 251, Multiclass F1: 0.521\n",
      "Epoch 252, Multiclass F1: 0.542\n",
      "Epoch 253, Multiclass F1: 0.525\n",
      "Epoch 254, Multiclass F1: 0.535\n",
      "Epoch 255, Multiclass F1: 0.505\n",
      "Epoch 256, Multiclass F1: 0.482\n",
      "Epoch 257, Multiclass F1: 0.535\n",
      "Epoch 258, Multiclass F1: 0.526\n",
      "Epoch 259, Multiclass F1: 0.545\n",
      "Epoch 260, Multiclass F1: 0.535\n",
      "Epoch 261, Multiclass F1: 0.535\n",
      "Epoch 262, Multiclass F1: 0.530\n",
      "Epoch 263, Multiclass F1: 0.526\n",
      "Epoch 264, Multiclass F1: 0.537\n",
      "Epoch 265, Multiclass F1: 0.513\n",
      "Epoch 266, Multiclass F1: 0.525\n",
      "Epoch 267, Multiclass F1: 0.524\n",
      "Epoch 268, Multiclass F1: 0.538\n",
      "Epoch 269, Multiclass F1: 0.534\n",
      "Epoch 270, Multiclass F1: 0.543\n",
      "Epoch 271, Multiclass F1: 0.530\n",
      "Epoch 272, Multiclass F1: 0.538\n",
      "Epoch 273, Multiclass F1: 0.521\n",
      "Epoch 274, Multiclass F1: 0.516\n",
      "Epoch 275, Multiclass F1: 0.542\n",
      "Epoch 276, Multiclass F1: 0.532\n",
      "Epoch 277, Multiclass F1: 0.542\n",
      "Epoch 278, Multiclass F1: 0.539\n",
      "Epoch 279, Multiclass F1: 0.521\n",
      "Epoch 280, Multiclass F1: 0.527\n",
      "Epoch 281, Multiclass F1: 0.542\n",
      "Epoch 282, Multiclass F1: 0.546\n",
      "Epoch 283, Multiclass F1: 0.525\n",
      "Epoch 284, Multiclass F1: 0.518\n",
      "Epoch 285, Multiclass F1: 0.527\n",
      "Epoch 286, Multiclass F1: 0.397\n",
      "Epoch 287, Multiclass F1: 0.534\n",
      "Epoch 288, Multiclass F1: 0.516\n",
      "Epoch 289, Multiclass F1: 0.515\n",
      "Epoch 290, Multiclass F1: 0.541\n",
      "Epoch 291, Multiclass F1: 0.540\n",
      "Epoch 292, Multiclass F1: 0.524\n",
      "Epoch 293, Multiclass F1: 0.540\n",
      "Epoch 294, Multiclass F1: 0.520\n",
      "Epoch 295, Multiclass F1: 0.544\n",
      "Epoch 296, Multiclass F1: 0.548\n",
      "Epoch 297, Multiclass F1: 0.542\n",
      "Epoch 298, Multiclass F1: 0.519\n",
      "Epoch 299, Multiclass F1: 0.543\n",
      "Epoch 300, Multiclass F1: 0.526\n",
      "Epoch 301, Multiclass F1: 0.531\n",
      "Epoch 302, Multiclass F1: 0.513\n",
      "Epoch 303, Multiclass F1: 0.532\n",
      "Epoch 304, Multiclass F1: 0.525\n",
      "Epoch 305, Multiclass F1: 0.536\n",
      "Epoch 306, Multiclass F1: 0.521\n",
      "Epoch 307, Multiclass F1: 0.540\n",
      "Epoch 308, Multiclass F1: 0.538\n",
      "Epoch 309, Multiclass F1: 0.534\n",
      "Epoch 310, Multiclass F1: 0.535\n",
      "Epoch 311, Multiclass F1: 0.529\n",
      "Epoch 312, Multiclass F1: 0.548\n",
      "Epoch 313, Multiclass F1: 0.529\n",
      "Epoch 314, Multiclass F1: 0.533\n",
      "Epoch 315, Multiclass F1: 0.539\n",
      "Epoch 316, Multiclass F1: 0.538\n",
      "Epoch 317, Multiclass F1: 0.494\n",
      "Epoch 318, Multiclass F1: 0.557\n",
      "Epoch 319, Multiclass F1: 0.517\n",
      "Epoch 320, Multiclass F1: 0.534\n",
      "Epoch 321, Multiclass F1: 0.423\n",
      "Epoch 322, Multiclass F1: 0.521\n",
      "Epoch 323, Multiclass F1: 0.527\n",
      "Epoch 324, Multiclass F1: 0.550\n",
      "Epoch 325, Multiclass F1: 0.534\n",
      "Epoch 326, Multiclass F1: 0.521\n",
      "Epoch 327, Multiclass F1: 0.534\n",
      "Epoch 328, Multiclass F1: 0.517\n",
      "Epoch 329, Multiclass F1: 0.540\n",
      "Epoch 330, Multiclass F1: 0.551\n",
      "Epoch 331, Multiclass F1: 0.546\n",
      "Epoch 332, Multiclass F1: 0.530\n",
      "Epoch 333, Multiclass F1: 0.544\n",
      "Epoch 334, Multiclass F1: 0.543\n",
      "Epoch 335, Multiclass F1: 0.536\n",
      "Epoch 336, Multiclass F1: 0.539\n",
      "Epoch 337, Multiclass F1: 0.549\n",
      "Epoch 338, Multiclass F1: 0.528\n",
      "Epoch 339, Multiclass F1: 0.542\n",
      "Epoch 340, Multiclass F1: 0.537\n",
      "Epoch 341, Multiclass F1: 0.537\n",
      "Epoch 342, Multiclass F1: 0.543\n",
      "Epoch 343, Multiclass F1: 0.532\n",
      "Epoch 344, Multiclass F1: 0.534\n",
      "Epoch 345, Multiclass F1: 0.534\n",
      "Epoch 346, Multiclass F1: 0.541\n",
      "Epoch 347, Multiclass F1: 0.548\n",
      "Epoch 348, Multiclass F1: 0.524\n",
      "Epoch 349, Multiclass F1: 0.488\n",
      "Epoch 350, Multiclass F1: 0.536\n",
      "Epoch 351, Multiclass F1: 0.529\n",
      "Epoch 352, Multiclass F1: 0.529\n",
      "Epoch 353, Multiclass F1: 0.542\n",
      "Epoch 354, Multiclass F1: 0.549\n",
      "Epoch 355, Multiclass F1: 0.544\n",
      "Epoch 356, Multiclass F1: 0.524\n",
      "Epoch 357, Multiclass F1: 0.542\n",
      "Epoch 358, Multiclass F1: 0.536\n",
      "Epoch 359, Multiclass F1: 0.514\n",
      "Epoch 360, Multiclass F1: 0.549\n",
      "Epoch 361, Multiclass F1: 0.549\n",
      "Epoch 362, Multiclass F1: 0.545\n",
      "Epoch 363, Multiclass F1: 0.538\n",
      "Epoch 364, Multiclass F1: 0.537\n",
      "Epoch 365, Multiclass F1: 0.524\n",
      "Epoch 366, Multiclass F1: 0.504\n",
      "Epoch 367, Multiclass F1: 0.528\n",
      "Epoch 368, Multiclass F1: 0.542\n",
      "Epoch 369, Multiclass F1: 0.544\n",
      "Epoch 370, Multiclass F1: 0.548\n",
      "Epoch 371, Multiclass F1: 0.522\n",
      "Epoch 372, Multiclass F1: 0.526\n",
      "Epoch 373, Multiclass F1: 0.517\n",
      "Epoch 374, Multiclass F1: 0.529\n",
      "Epoch 375, Multiclass F1: 0.524\n",
      "Epoch 376, Multiclass F1: 0.544\n",
      "Epoch 377, Multiclass F1: 0.522\n",
      "Epoch 378, Multiclass F1: 0.524\n",
      "Epoch 379, Multiclass F1: 0.552\n",
      "Epoch 380, Multiclass F1: 0.540\n",
      "Epoch 381, Multiclass F1: 0.522\n",
      "Epoch 382, Multiclass F1: 0.546\n",
      "Epoch 383, Multiclass F1: 0.545\n",
      "Epoch 384, Multiclass F1: 0.538\n",
      "Epoch 385, Multiclass F1: 0.539\n",
      "Epoch 386, Multiclass F1: 0.540\n",
      "Epoch 387, Multiclass F1: 0.524\n",
      "Epoch 388, Multiclass F1: 0.530\n",
      "Epoch 389, Multiclass F1: 0.532\n",
      "Epoch 390, Multiclass F1: 0.540\n",
      "Epoch 391, Multiclass F1: 0.534\n",
      "Epoch 392, Multiclass F1: 0.537\n",
      "Epoch 393, Multiclass F1: 0.548\n",
      "Epoch 394, Multiclass F1: 0.543\n",
      "Epoch 395, Multiclass F1: 0.541\n",
      "Epoch 396, Multiclass F1: 0.533\n",
      "Epoch 397, Multiclass F1: 0.526\n",
      "Epoch 398, Multiclass F1: 0.546\n",
      "Epoch 399, Multiclass F1: 0.530\n",
      "Epoch 400, Multiclass F1: 0.543\n",
      "Epoch 401, Multiclass F1: 0.543\n",
      "Epoch 402, Multiclass F1: 0.543\n",
      "Epoch 403, Multiclass F1: 0.545\n",
      "Epoch 404, Multiclass F1: 0.541\n",
      "Epoch 405, Multiclass F1: 0.537\n",
      "Epoch 406, Multiclass F1: 0.517\n",
      "Epoch 407, Multiclass F1: 0.545\n",
      "Epoch 408, Multiclass F1: 0.541\n",
      "Epoch 409, Multiclass F1: 0.542\n",
      "Epoch 410, Multiclass F1: 0.497\n",
      "Epoch 411, Multiclass F1: 0.540\n",
      "Epoch 412, Multiclass F1: 0.552\n",
      "Epoch 413, Multiclass F1: 0.556\n",
      "Epoch 414, Multiclass F1: 0.538\n",
      "Epoch 415, Multiclass F1: 0.543\n",
      "Epoch 416, Multiclass F1: 0.543\n",
      "Epoch 417, Multiclass F1: 0.528\n",
      "Epoch 418, Multiclass F1: 0.548\n",
      "Epoch 419, Multiclass F1: 0.528\n",
      "Epoch 420, Multiclass F1: 0.545\n",
      "Epoch 421, Multiclass F1: 0.556\n",
      "Epoch 422, Multiclass F1: 0.542\n",
      "Epoch 423, Multiclass F1: 0.468\n",
      "Epoch 424, Multiclass F1: 0.538\n",
      "Epoch 425, Multiclass F1: 0.539\n",
      "Epoch 426, Multiclass F1: 0.542\n",
      "Epoch 427, Multiclass F1: 0.550\n",
      "Epoch 428, Multiclass F1: 0.539\n",
      "Epoch 429, Multiclass F1: 0.546\n",
      "Epoch 430, Multiclass F1: 0.542\n",
      "Epoch 431, Multiclass F1: 0.546\n",
      "Epoch 432, Multiclass F1: 0.534\n",
      "Epoch 433, Multiclass F1: 0.550\n",
      "Epoch 434, Multiclass F1: 0.547\n",
      "Epoch 435, Multiclass F1: 0.553\n",
      "Epoch 436, Multiclass F1: 0.557\n",
      "Epoch 437, Multiclass F1: 0.548\n",
      "Epoch 438, Multiclass F1: 0.548\n",
      "Epoch 439, Multiclass F1: 0.542\n",
      "Epoch 440, Multiclass F1: 0.530\n",
      "Epoch 441, Multiclass F1: 0.539\n",
      "Epoch 442, Multiclass F1: 0.548\n",
      "Epoch 443, Multiclass F1: 0.550\n",
      "Epoch 444, Multiclass F1: 0.535\n",
      "Epoch 445, Multiclass F1: 0.546\n",
      "Epoch 446, Multiclass F1: 0.550\n",
      "Epoch 447, Multiclass F1: 0.546\n",
      "Epoch 448, Multiclass F1: 0.542\n",
      "Epoch 449, Multiclass F1: 0.546\n",
      "Epoch 450, Multiclass F1: 0.548\n",
      "Epoch 451, Multiclass F1: 0.547\n",
      "Epoch 452, Multiclass F1: 0.544\n",
      "Epoch 453, Multiclass F1: 0.553\n",
      "Epoch 454, Multiclass F1: 0.545\n",
      "Epoch 455, Multiclass F1: 0.544\n",
      "Epoch 456, Multiclass F1: 0.540\n",
      "Epoch 457, Multiclass F1: 0.541\n",
      "Epoch 458, Multiclass F1: 0.549\n",
      "Epoch 459, Multiclass F1: 0.511\n",
      "Epoch 460, Multiclass F1: 0.553\n",
      "Epoch 461, Multiclass F1: 0.534\n",
      "Epoch 462, Multiclass F1: 0.544\n",
      "Epoch 463, Multiclass F1: 0.539\n",
      "Epoch 464, Multiclass F1: 0.550\n",
      "Epoch 465, Multiclass F1: 0.542\n",
      "Epoch 466, Multiclass F1: 0.537\n",
      "Epoch 467, Multiclass F1: 0.540\n",
      "Epoch 468, Multiclass F1: 0.517\n",
      "Epoch 469, Multiclass F1: 0.546\n",
      "Epoch 470, Multiclass F1: 0.540\n",
      "Epoch 471, Multiclass F1: 0.524\n",
      "Epoch 472, Multiclass F1: 0.545\n",
      "Epoch 473, Multiclass F1: 0.515\n",
      "Epoch 474, Multiclass F1: 0.512\n",
      "Epoch 475, Multiclass F1: 0.548\n",
      "Epoch 476, Multiclass F1: 0.550\n",
      "Epoch 477, Multiclass F1: 0.521\n",
      "Epoch 478, Multiclass F1: 0.554\n",
      "Epoch 479, Multiclass F1: 0.545\n",
      "Epoch 480, Multiclass F1: 0.544\n",
      "Epoch 481, Multiclass F1: 0.543\n",
      "Epoch 482, Multiclass F1: 0.532\n",
      "Epoch 483, Multiclass F1: 0.538\n",
      "Epoch 484, Multiclass F1: 0.523\n",
      "Epoch 485, Multiclass F1: 0.549\n",
      "Epoch 486, Multiclass F1: 0.541\n",
      "Epoch 487, Multiclass F1: 0.544\n",
      "Epoch 488, Multiclass F1: 0.542\n",
      "Epoch 489, Multiclass F1: 0.534\n",
      "Epoch 490, Multiclass F1: 0.549\n",
      "Epoch 491, Multiclass F1: 0.555\n",
      "Epoch 492, Multiclass F1: 0.544\n",
      "Epoch 493, Multiclass F1: 0.556\n",
      "Epoch 494, Multiclass F1: 0.542\n",
      "Epoch 495, Multiclass F1: 0.534\n",
      "Epoch 496, Multiclass F1: 0.552\n",
      "Epoch 497, Multiclass F1: 0.551\n",
      "Epoch 498, Multiclass F1: 0.541\n",
      "Epoch 499, Multiclass F1: 0.546\n",
      "Epoch 500, Multiclass F1: 0.540\n",
      "Epoch 501, Multiclass F1: 0.539\n",
      "Epoch 502, Multiclass F1: 0.541\n",
      "Epoch 503, Multiclass F1: 0.542\n",
      "Epoch 504, Multiclass F1: 0.529\n",
      "Epoch 505, Multiclass F1: 0.527\n",
      "Epoch 506, Multiclass F1: 0.522\n",
      "Epoch 507, Multiclass F1: 0.548\n",
      "Epoch 508, Multiclass F1: 0.547\n",
      "Epoch 509, Multiclass F1: 0.521\n",
      "Epoch 510, Multiclass F1: 0.552\n",
      "Epoch 511, Multiclass F1: 0.549\n",
      "Epoch 512, Multiclass F1: 0.520\n",
      "Epoch 513, Multiclass F1: 0.526\n",
      "Epoch 514, Multiclass F1: 0.547\n",
      "Epoch 515, Multiclass F1: 0.540\n",
      "Epoch 516, Multiclass F1: 0.548\n",
      "Epoch 517, Multiclass F1: 0.548\n",
      "Epoch 518, Multiclass F1: 0.530\n",
      "Epoch 519, Multiclass F1: 0.552\n",
      "Epoch 520, Multiclass F1: 0.538\n",
      "Epoch 521, Multiclass F1: 0.546\n",
      "Epoch 522, Multiclass F1: 0.537\n",
      "Epoch 523, Multiclass F1: 0.538\n",
      "Epoch 524, Multiclass F1: 0.537\n",
      "Epoch 525, Multiclass F1: 0.547\n",
      "Epoch 526, Multiclass F1: 0.540\n",
      "Epoch 527, Multiclass F1: 0.514\n",
      "Epoch 528, Multiclass F1: 0.531\n",
      "Epoch 529, Multiclass F1: 0.534\n",
      "Epoch 530, Multiclass F1: 0.555\n",
      "Epoch 531, Multiclass F1: 0.557\n",
      "Epoch 532, Multiclass F1: 0.539\n",
      "Epoch 533, Multiclass F1: 0.505\n",
      "Epoch 534, Multiclass F1: 0.544\n",
      "Epoch 535, Multiclass F1: 0.538\n",
      "Epoch 536, Multiclass F1: 0.555\n",
      "Epoch 537, Multiclass F1: 0.551\n",
      "Epoch 538, Multiclass F1: 0.531\n",
      "Epoch 539, Multiclass F1: 0.549\n",
      "Epoch 540, Multiclass F1: 0.536\n",
      "Epoch 541, Multiclass F1: 0.550\n",
      "Epoch 542, Multiclass F1: 0.544\n",
      "Epoch 543, Multiclass F1: 0.555\n",
      "Epoch 544, Multiclass F1: 0.521\n",
      "Epoch 545, Multiclass F1: 0.543\n",
      "Epoch 546, Multiclass F1: 0.554\n",
      "Epoch 547, Multiclass F1: 0.525\n",
      "Epoch 548, Multiclass F1: 0.556\n",
      "Epoch 549, Multiclass F1: 0.554\n",
      "Epoch 550, Multiclass F1: 0.549\n",
      "Epoch 551, Multiclass F1: 0.532\n",
      "Epoch 552, Multiclass F1: 0.540\n",
      "Epoch 553, Multiclass F1: 0.543\n",
      "Epoch 554, Multiclass F1: 0.556\n",
      "Epoch 555, Multiclass F1: 0.531\n",
      "Epoch 556, Multiclass F1: 0.533\n",
      "Epoch 557, Multiclass F1: 0.545\n",
      "Epoch 558, Multiclass F1: 0.559\n",
      "Epoch 559, Multiclass F1: 0.558\n",
      "Epoch 560, Multiclass F1: 0.540\n",
      "Epoch 561, Multiclass F1: 0.548\n",
      "Epoch 562, Multiclass F1: 0.546\n",
      "Epoch 563, Multiclass F1: 0.546\n",
      "Epoch 564, Multiclass F1: 0.544\n",
      "Epoch 565, Multiclass F1: 0.549\n",
      "Epoch 566, Multiclass F1: 0.551\n",
      "Epoch 567, Multiclass F1: 0.537\n",
      "Epoch 568, Multiclass F1: 0.549\n",
      "Epoch 569, Multiclass F1: 0.545\n",
      "Epoch 570, Multiclass F1: 0.552\n",
      "Epoch 571, Multiclass F1: 0.566\n",
      "Epoch 572, Multiclass F1: 0.556\n",
      "Epoch 573, Multiclass F1: 0.528\n",
      "Epoch 574, Multiclass F1: 0.536\n",
      "Epoch 575, Multiclass F1: 0.550\n",
      "Epoch 576, Multiclass F1: 0.551\n",
      "Epoch 577, Multiclass F1: 0.550\n",
      "Epoch 578, Multiclass F1: 0.535\n",
      "Epoch 579, Multiclass F1: 0.552\n",
      "Epoch 580, Multiclass F1: 0.558\n",
      "Epoch 581, Multiclass F1: 0.529\n",
      "Epoch 582, Multiclass F1: 0.549\n",
      "Epoch 583, Multiclass F1: 0.548\n",
      "Epoch 584, Multiclass F1: 0.557\n",
      "Epoch 585, Multiclass F1: 0.544\n",
      "Epoch 586, Multiclass F1: 0.550\n",
      "Epoch 587, Multiclass F1: 0.544\n",
      "Epoch 588, Multiclass F1: 0.532\n",
      "Epoch 589, Multiclass F1: 0.545\n",
      "Epoch 590, Multiclass F1: 0.557\n",
      "Epoch 591, Multiclass F1: 0.553\n",
      "Epoch 592, Multiclass F1: 0.524\n",
      "Epoch 593, Multiclass F1: 0.563\n",
      "Epoch 594, Multiclass F1: 0.545\n",
      "Epoch 595, Multiclass F1: 0.515\n",
      "Epoch 596, Multiclass F1: 0.536\n",
      "Epoch 597, Multiclass F1: 0.549\n",
      "Epoch 598, Multiclass F1: 0.538\n",
      "Epoch 599, Multiclass F1: 0.550\n",
      "Epoch 600, Multiclass F1: 0.550\n",
      "Epoch 601, Multiclass F1: 0.555\n",
      "Epoch 602, Multiclass F1: 0.558\n",
      "Epoch 603, Multiclass F1: 0.536\n",
      "Epoch 604, Multiclass F1: 0.529\n",
      "Epoch 605, Multiclass F1: 0.543\n",
      "Epoch 606, Multiclass F1: 0.541\n",
      "Epoch 607, Multiclass F1: 0.548\n",
      "Epoch 608, Multiclass F1: 0.553\n",
      "Epoch 609, Multiclass F1: 0.560\n",
      "Epoch 610, Multiclass F1: 0.541\n",
      "Epoch 611, Multiclass F1: 0.550\n",
      "Epoch 612, Multiclass F1: 0.545\n",
      "Epoch 613, Multiclass F1: 0.521\n",
      "Epoch 614, Multiclass F1: 0.555\n",
      "Epoch 615, Multiclass F1: 0.551\n",
      "Epoch 616, Multiclass F1: 0.552\n",
      "Epoch 617, Multiclass F1: 0.554\n",
      "Epoch 618, Multiclass F1: 0.558\n",
      "Epoch 619, Multiclass F1: 0.551\n",
      "Epoch 620, Multiclass F1: 0.528\n",
      "Epoch 621, Multiclass F1: 0.538\n",
      "Epoch 622, Multiclass F1: 0.547\n",
      "Epoch 623, Multiclass F1: 0.554\n",
      "Epoch 624, Multiclass F1: 0.551\n",
      "Epoch 625, Multiclass F1: 0.546\n",
      "Epoch 626, Multiclass F1: 0.557\n",
      "Epoch 627, Multiclass F1: 0.566\n",
      "Epoch 628, Multiclass F1: 0.546\n",
      "Epoch 629, Multiclass F1: 0.538\n",
      "Epoch 630, Multiclass F1: 0.537\n",
      "Epoch 631, Multiclass F1: 0.567\n",
      "Epoch 632, Multiclass F1: 0.529\n",
      "Epoch 633, Multiclass F1: 0.555\n",
      "Epoch 634, Multiclass F1: 0.549\n",
      "Epoch 635, Multiclass F1: 0.539\n",
      "Epoch 636, Multiclass F1: 0.558\n",
      "Epoch 637, Multiclass F1: 0.559\n",
      "Epoch 638, Multiclass F1: 0.554\n",
      "Epoch 639, Multiclass F1: 0.547\n",
      "Epoch 640, Multiclass F1: 0.562\n",
      "Epoch 641, Multiclass F1: 0.541\n",
      "Epoch 642, Multiclass F1: 0.539\n",
      "Epoch 643, Multiclass F1: 0.559\n",
      "Epoch 644, Multiclass F1: 0.525\n",
      "Epoch 645, Multiclass F1: 0.545\n",
      "Epoch 646, Multiclass F1: 0.554\n",
      "Epoch 647, Multiclass F1: 0.533\n",
      "Epoch 648, Multiclass F1: 0.562\n",
      "Epoch 649, Multiclass F1: 0.547\n",
      "Epoch 650, Multiclass F1: 0.556\n",
      "Epoch 651, Multiclass F1: 0.556\n",
      "Epoch 652, Multiclass F1: 0.553\n",
      "Epoch 653, Multiclass F1: 0.563\n",
      "Epoch 654, Multiclass F1: 0.547\n",
      "Epoch 655, Multiclass F1: 0.552\n",
      "Epoch 656, Multiclass F1: 0.562\n",
      "Epoch 657, Multiclass F1: 0.555\n",
      "Epoch 658, Multiclass F1: 0.521\n",
      "Epoch 659, Multiclass F1: 0.551\n",
      "Epoch 660, Multiclass F1: 0.557\n",
      "Epoch 661, Multiclass F1: 0.559\n",
      "Epoch 662, Multiclass F1: 0.557\n",
      "Epoch 663, Multiclass F1: 0.539\n",
      "Epoch 664, Multiclass F1: 0.552\n",
      "Epoch 665, Multiclass F1: 0.553\n",
      "Epoch 666, Multiclass F1: 0.539\n",
      "Epoch 667, Multiclass F1: 0.554\n",
      "Epoch 668, Multiclass F1: 0.560\n",
      "Epoch 669, Multiclass F1: 0.540\n",
      "Epoch 670, Multiclass F1: 0.542\n",
      "Epoch 671, Multiclass F1: 0.533\n",
      "Epoch 672, Multiclass F1: 0.556\n",
      "Epoch 673, Multiclass F1: 0.544\n",
      "Epoch 674, Multiclass F1: 0.556\n",
      "Epoch 675, Multiclass F1: 0.549\n",
      "Epoch 676, Multiclass F1: 0.542\n",
      "Epoch 677, Multiclass F1: 0.563\n",
      "Epoch 678, Multiclass F1: 0.558\n",
      "Epoch 679, Multiclass F1: 0.543\n",
      "Epoch 680, Multiclass F1: 0.557\n",
      "Epoch 681, Multiclass F1: 0.551\n",
      "Epoch 682, Multiclass F1: 0.550\n",
      "Epoch 683, Multiclass F1: 0.524\n",
      "Epoch 684, Multiclass F1: 0.556\n",
      "Epoch 685, Multiclass F1: 0.504\n",
      "Epoch 686, Multiclass F1: 0.555\n",
      "Epoch 687, Multiclass F1: 0.541\n",
      "Epoch 688, Multiclass F1: 0.568\n",
      "Epoch 689, Multiclass F1: 0.555\n",
      "Epoch 690, Multiclass F1: 0.533\n",
      "Epoch 691, Multiclass F1: 0.550\n",
      "Epoch 692, Multiclass F1: 0.548\n",
      "Epoch 693, Multiclass F1: 0.556\n",
      "Epoch 694, Multiclass F1: 0.553\n",
      "Epoch 695, Multiclass F1: 0.557\n",
      "Epoch 696, Multiclass F1: 0.551\n",
      "Epoch 697, Multiclass F1: 0.561\n",
      "Epoch 698, Multiclass F1: 0.557\n",
      "Epoch 699, Multiclass F1: 0.556\n",
      "Epoch 700, Multiclass F1: 0.554\n",
      "Epoch 701, Multiclass F1: 0.555\n",
      "Epoch 702, Multiclass F1: 0.555\n",
      "Epoch 703, Multiclass F1: 0.536\n",
      "Epoch 704, Multiclass F1: 0.538\n",
      "Epoch 705, Multiclass F1: 0.560\n",
      "Epoch 706, Multiclass F1: 0.551\n",
      "Epoch 707, Multiclass F1: 0.525\n",
      "Epoch 708, Multiclass F1: 0.557\n",
      "Epoch 709, Multiclass F1: 0.555\n",
      "Epoch 710, Multiclass F1: 0.557\n",
      "Epoch 711, Multiclass F1: 0.522\n",
      "Epoch 712, Multiclass F1: 0.565\n",
      "Epoch 713, Multiclass F1: 0.550\n",
      "Epoch 714, Multiclass F1: 0.540\n",
      "Epoch 715, Multiclass F1: 0.542\n",
      "Epoch 716, Multiclass F1: 0.553\n",
      "Epoch 717, Multiclass F1: 0.573\n",
      "Epoch 718, Multiclass F1: 0.555\n",
      "Epoch 719, Multiclass F1: 0.536\n",
      "Epoch 720, Multiclass F1: 0.549\n",
      "Epoch 721, Multiclass F1: 0.562\n",
      "Epoch 722, Multiclass F1: 0.560\n",
      "Epoch 723, Multiclass F1: 0.565\n",
      "Epoch 724, Multiclass F1: 0.559\n",
      "Epoch 725, Multiclass F1: 0.564\n",
      "Epoch 726, Multiclass F1: 0.531\n",
      "Epoch 727, Multiclass F1: 0.537\n",
      "Epoch 728, Multiclass F1: 0.560\n",
      "Epoch 729, Multiclass F1: 0.543\n",
      "Epoch 730, Multiclass F1: 0.556\n",
      "Epoch 731, Multiclass F1: 0.552\n",
      "Epoch 732, Multiclass F1: 0.543\n",
      "Epoch 733, Multiclass F1: 0.565\n",
      "Epoch 734, Multiclass F1: 0.554\n",
      "Epoch 735, Multiclass F1: 0.562\n",
      "Epoch 736, Multiclass F1: 0.555\n",
      "Epoch 737, Multiclass F1: 0.557\n",
      "Epoch 738, Multiclass F1: 0.547\n",
      "Epoch 739, Multiclass F1: 0.555\n",
      "Epoch 740, Multiclass F1: 0.549\n",
      "Epoch 741, Multiclass F1: 0.565\n",
      "Epoch 742, Multiclass F1: 0.560\n",
      "Epoch 743, Multiclass F1: 0.529\n",
      "Epoch 744, Multiclass F1: 0.555\n",
      "Epoch 745, Multiclass F1: 0.547\n",
      "Epoch 746, Multiclass F1: 0.498\n",
      "Epoch 747, Multiclass F1: 0.565\n",
      "Epoch 748, Multiclass F1: 0.552\n",
      "Epoch 749, Multiclass F1: 0.537\n",
      "Epoch 750, Multiclass F1: 0.549\n",
      "Epoch 751, Multiclass F1: 0.561\n",
      "Epoch 752, Multiclass F1: 0.564\n",
      "Epoch 753, Multiclass F1: 0.558\n",
      "Epoch 754, Multiclass F1: 0.545\n",
      "Epoch 755, Multiclass F1: 0.554\n",
      "Epoch 756, Multiclass F1: 0.556\n",
      "Epoch 757, Multiclass F1: 0.559\n",
      "Epoch 758, Multiclass F1: 0.571\n",
      "Epoch 759, Multiclass F1: 0.556\n",
      "Epoch 760, Multiclass F1: 0.557\n",
      "Epoch 761, Multiclass F1: 0.555\n",
      "Epoch 762, Multiclass F1: 0.563\n",
      "Epoch 763, Multiclass F1: 0.531\n",
      "Epoch 764, Multiclass F1: 0.556\n",
      "Epoch 765, Multiclass F1: 0.540\n",
      "Epoch 766, Multiclass F1: 0.412\n",
      "Epoch 767, Multiclass F1: 0.559\n",
      "Epoch 768, Multiclass F1: 0.549\n",
      "Epoch 769, Multiclass F1: 0.538\n",
      "Epoch 770, Multiclass F1: 0.535\n",
      "Epoch 771, Multiclass F1: 0.559\n",
      "Epoch 772, Multiclass F1: 0.554\n",
      "Epoch 773, Multiclass F1: 0.560\n",
      "Epoch 774, Multiclass F1: 0.558\n",
      "Epoch 775, Multiclass F1: 0.553\n",
      "Epoch 776, Multiclass F1: 0.548\n",
      "Epoch 777, Multiclass F1: 0.546\n",
      "Epoch 778, Multiclass F1: 0.541\n",
      "Epoch 779, Multiclass F1: 0.559\n",
      "Epoch 780, Multiclass F1: 0.543\n",
      "Epoch 781, Multiclass F1: 0.545\n",
      "Epoch 782, Multiclass F1: 0.550\n",
      "Epoch 783, Multiclass F1: 0.561\n",
      "Epoch 784, Multiclass F1: 0.542\n",
      "Epoch 785, Multiclass F1: 0.570\n",
      "Epoch 786, Multiclass F1: 0.553\n",
      "Epoch 787, Multiclass F1: 0.561\n",
      "Epoch 788, Multiclass F1: 0.558\n",
      "Epoch 789, Multiclass F1: 0.554\n",
      "Epoch 790, Multiclass F1: 0.552\n",
      "Epoch 791, Multiclass F1: 0.551\n",
      "Epoch 792, Multiclass F1: 0.553\n",
      "Epoch 793, Multiclass F1: 0.546\n",
      "Epoch 794, Multiclass F1: 0.546\n",
      "Epoch 795, Multiclass F1: 0.534\n",
      "Epoch 796, Multiclass F1: 0.538\n",
      "Epoch 797, Multiclass F1: 0.557\n",
      "Epoch 798, Multiclass F1: 0.558\n",
      "Epoch 799, Multiclass F1: 0.561\n",
      "Epoch 800, Multiclass F1: 0.543\n",
      "Epoch 801, Multiclass F1: 0.562\n",
      "Epoch 802, Multiclass F1: 0.530\n",
      "Epoch 803, Multiclass F1: 0.557\n",
      "Epoch 804, Multiclass F1: 0.555\n",
      "Epoch 805, Multiclass F1: 0.552\n",
      "Epoch 806, Multiclass F1: 0.561\n",
      "Epoch 807, Multiclass F1: 0.554\n",
      "Epoch 808, Multiclass F1: 0.548\n",
      "Epoch 809, Multiclass F1: 0.566\n",
      "Epoch 810, Multiclass F1: 0.539\n",
      "Epoch 811, Multiclass F1: 0.565\n",
      "Epoch 812, Multiclass F1: 0.560\n",
      "Epoch 813, Multiclass F1: 0.564\n",
      "Epoch 814, Multiclass F1: 0.569\n",
      "Epoch 815, Multiclass F1: 0.568\n",
      "Epoch 816, Multiclass F1: 0.545\n",
      "Epoch 817, Multiclass F1: 0.553\n",
      "Epoch 818, Multiclass F1: 0.560\n",
      "Epoch 819, Multiclass F1: 0.562\n",
      "Epoch 820, Multiclass F1: 0.563\n",
      "Epoch 821, Multiclass F1: 0.560\n",
      "Epoch 822, Multiclass F1: 0.554\n",
      "Epoch 823, Multiclass F1: 0.544\n",
      "Epoch 824, Multiclass F1: 0.554\n",
      "Epoch 825, Multiclass F1: 0.538\n",
      "Epoch 826, Multiclass F1: 0.549\n",
      "Epoch 827, Multiclass F1: 0.555\n",
      "Epoch 828, Multiclass F1: 0.562\n",
      "Epoch 829, Multiclass F1: 0.552\n",
      "Epoch 830, Multiclass F1: 0.568\n",
      "Epoch 831, Multiclass F1: 0.558\n",
      "Epoch 832, Multiclass F1: 0.544\n",
      "Epoch 833, Multiclass F1: 0.557\n",
      "Epoch 834, Multiclass F1: 0.558\n",
      "Epoch 835, Multiclass F1: 0.565\n",
      "Epoch 836, Multiclass F1: 0.543\n",
      "Epoch 837, Multiclass F1: 0.552\n",
      "Epoch 838, Multiclass F1: 0.561\n",
      "Epoch 839, Multiclass F1: 0.520\n",
      "Epoch 840, Multiclass F1: 0.555\n",
      "Epoch 841, Multiclass F1: 0.567\n",
      "Epoch 842, Multiclass F1: 0.559\n",
      "Epoch 843, Multiclass F1: 0.556\n",
      "Epoch 844, Multiclass F1: 0.548\n",
      "Epoch 845, Multiclass F1: 0.567\n",
      "Epoch 846, Multiclass F1: 0.561\n",
      "Epoch 847, Multiclass F1: 0.549\n",
      "Epoch 848, Multiclass F1: 0.550\n",
      "Epoch 849, Multiclass F1: 0.548\n",
      "Epoch 850, Multiclass F1: 0.567\n",
      "Epoch 851, Multiclass F1: 0.557\n",
      "Epoch 852, Multiclass F1: 0.558\n",
      "Epoch 853, Multiclass F1: 0.566\n",
      "Epoch 854, Multiclass F1: 0.558\n",
      "Epoch 855, Multiclass F1: 0.554\n",
      "Epoch 856, Multiclass F1: 0.554\n",
      "Epoch 857, Multiclass F1: 0.553\n",
      "Epoch 858, Multiclass F1: 0.566\n",
      "Epoch 859, Multiclass F1: 0.561\n",
      "Epoch 860, Multiclass F1: 0.558\n",
      "Epoch 861, Multiclass F1: 0.540\n",
      "Epoch 862, Multiclass F1: 0.562\n",
      "Epoch 863, Multiclass F1: 0.558\n",
      "Epoch 864, Multiclass F1: 0.550\n",
      "Epoch 865, Multiclass F1: 0.549\n",
      "Epoch 866, Multiclass F1: 0.551\n",
      "Epoch 867, Multiclass F1: 0.558\n",
      "Epoch 868, Multiclass F1: 0.539\n",
      "Epoch 869, Multiclass F1: 0.553\n",
      "Epoch 870, Multiclass F1: 0.541\n",
      "Epoch 871, Multiclass F1: 0.535\n",
      "Epoch 872, Multiclass F1: 0.568\n",
      "Epoch 873, Multiclass F1: 0.557\n",
      "Epoch 874, Multiclass F1: 0.546\n",
      "Epoch 875, Multiclass F1: 0.555\n",
      "Epoch 876, Multiclass F1: 0.564\n",
      "Epoch 877, Multiclass F1: 0.552\n",
      "Epoch 878, Multiclass F1: 0.569\n",
      "Epoch 879, Multiclass F1: 0.560\n",
      "Epoch 880, Multiclass F1: 0.565\n",
      "Epoch 881, Multiclass F1: 0.574\n",
      "Epoch 882, Multiclass F1: 0.553\n",
      "Epoch 883, Multiclass F1: 0.531\n",
      "Epoch 884, Multiclass F1: 0.560\n",
      "Epoch 885, Multiclass F1: 0.548\n",
      "Epoch 886, Multiclass F1: 0.558\n",
      "Epoch 887, Multiclass F1: 0.551\n",
      "Epoch 888, Multiclass F1: 0.564\n",
      "Epoch 889, Multiclass F1: 0.548\n",
      "Epoch 890, Multiclass F1: 0.552\n",
      "Epoch 891, Multiclass F1: 0.559\n",
      "Epoch 892, Multiclass F1: 0.557\n",
      "Epoch 893, Multiclass F1: 0.575\n",
      "Epoch 894, Multiclass F1: 0.552\n",
      "Epoch 895, Multiclass F1: 0.559\n",
      "Epoch 896, Multiclass F1: 0.561\n",
      "Epoch 897, Multiclass F1: 0.554\n",
      "Epoch 898, Multiclass F1: 0.543\n",
      "Epoch 899, Multiclass F1: 0.567\n",
      "Epoch 900, Multiclass F1: 0.566\n",
      "Epoch 901, Multiclass F1: 0.539\n",
      "Epoch 902, Multiclass F1: 0.558\n",
      "Epoch 903, Multiclass F1: 0.563\n",
      "Epoch 904, Multiclass F1: 0.564\n",
      "Epoch 905, Multiclass F1: 0.567\n",
      "Epoch 906, Multiclass F1: 0.553\n",
      "Epoch 907, Multiclass F1: 0.547\n",
      "Epoch 908, Multiclass F1: 0.556\n",
      "Epoch 909, Multiclass F1: 0.571\n",
      "Epoch 910, Multiclass F1: 0.569\n",
      "Epoch 911, Multiclass F1: 0.562\n",
      "Epoch 912, Multiclass F1: 0.550\n",
      "Epoch 913, Multiclass F1: 0.554\n",
      "Epoch 914, Multiclass F1: 0.556\n",
      "Epoch 915, Multiclass F1: 0.559\n",
      "Epoch 916, Multiclass F1: 0.553\n",
      "Epoch 917, Multiclass F1: 0.562\n",
      "Epoch 918, Multiclass F1: 0.556\n",
      "Epoch 919, Multiclass F1: 0.543\n",
      "Epoch 920, Multiclass F1: 0.546\n",
      "Epoch 921, Multiclass F1: 0.555\n",
      "Epoch 922, Multiclass F1: 0.558\n",
      "Epoch 923, Multiclass F1: 0.559\n",
      "Epoch 924, Multiclass F1: 0.576\n",
      "Epoch 925, Multiclass F1: 0.554\n",
      "Epoch 926, Multiclass F1: 0.550\n",
      "Epoch 927, Multiclass F1: 0.556\n",
      "Epoch 928, Multiclass F1: 0.556\n",
      "Epoch 929, Multiclass F1: 0.518\n",
      "Epoch 930, Multiclass F1: 0.554\n",
      "Epoch 931, Multiclass F1: 0.539\n",
      "Epoch 932, Multiclass F1: 0.551\n",
      "Epoch 933, Multiclass F1: 0.557\n",
      "Epoch 934, Multiclass F1: 0.569\n",
      "Epoch 935, Multiclass F1: 0.523\n",
      "Epoch 936, Multiclass F1: 0.544\n",
      "Epoch 937, Multiclass F1: 0.548\n",
      "Epoch 938, Multiclass F1: 0.549\n",
      "Epoch 939, Multiclass F1: 0.562\n",
      "Epoch 940, Multiclass F1: 0.569\n",
      "Epoch 941, Multiclass F1: 0.563\n",
      "Epoch 942, Multiclass F1: 0.556\n",
      "Epoch 943, Multiclass F1: 0.564\n",
      "Epoch 944, Multiclass F1: 0.554\n",
      "Epoch 945, Multiclass F1: 0.562\n",
      "Epoch 946, Multiclass F1: 0.560\n",
      "Epoch 947, Multiclass F1: 0.563\n",
      "Epoch 948, Multiclass F1: 0.539\n",
      "Epoch 949, Multiclass F1: 0.561\n",
      "Epoch 950, Multiclass F1: 0.559\n",
      "Epoch 951, Multiclass F1: 0.577\n",
      "Epoch 952, Multiclass F1: 0.561\n",
      "Epoch 953, Multiclass F1: 0.531\n",
      "Epoch 954, Multiclass F1: 0.551\n",
      "Epoch 955, Multiclass F1: 0.563\n",
      "Epoch 956, Multiclass F1: 0.561\n",
      "Epoch 957, Multiclass F1: 0.564\n",
      "Epoch 958, Multiclass F1: 0.566\n",
      "Epoch 959, Multiclass F1: 0.573\n",
      "Epoch 960, Multiclass F1: 0.549\n",
      "Epoch 961, Multiclass F1: 0.563\n",
      "Epoch 962, Multiclass F1: 0.563\n",
      "Epoch 963, Multiclass F1: 0.551\n",
      "Epoch 964, Multiclass F1: 0.561\n",
      "Epoch 965, Multiclass F1: 0.556\n",
      "Epoch 966, Multiclass F1: 0.564\n",
      "Epoch 967, Multiclass F1: 0.577\n",
      "Epoch 968, Multiclass F1: 0.564\n",
      "Epoch 969, Multiclass F1: 0.554\n",
      "Epoch 970, Multiclass F1: 0.548\n",
      "Epoch 971, Multiclass F1: 0.536\n",
      "Epoch 972, Multiclass F1: 0.550\n",
      "Epoch 973, Multiclass F1: 0.562\n",
      "Epoch 974, Multiclass F1: 0.536\n",
      "Epoch 975, Multiclass F1: 0.541\n",
      "Epoch 976, Multiclass F1: 0.561\n",
      "Epoch 977, Multiclass F1: 0.552\n",
      "Epoch 978, Multiclass F1: 0.553\n",
      "Epoch 979, Multiclass F1: 0.559\n",
      "Epoch 980, Multiclass F1: 0.563\n",
      "Epoch 981, Multiclass F1: 0.557\n",
      "Epoch 982, Multiclass F1: 0.568\n",
      "Epoch 983, Multiclass F1: 0.566\n",
      "Epoch 984, Multiclass F1: 0.566\n",
      "Epoch 985, Multiclass F1: 0.555\n",
      "Epoch 986, Multiclass F1: 0.535\n",
      "Epoch 987, Multiclass F1: 0.561\n",
      "Epoch 988, Multiclass F1: 0.545\n",
      "Epoch 989, Multiclass F1: 0.552\n",
      "Epoch 990, Multiclass F1: 0.556\n",
      "Epoch 991, Multiclass F1: 0.566\n",
      "Epoch 992, Multiclass F1: 0.559\n",
      "Epoch 993, Multiclass F1: 0.562\n",
      "Epoch 994, Multiclass F1: 0.552\n",
      "Epoch 995, Multiclass F1: 0.564\n",
      "Epoch 996, Multiclass F1: 0.572\n",
      "Epoch 997, Multiclass F1: 0.551\n",
      "Epoch 998, Multiclass F1: 0.548\n",
      "Epoch 999, Multiclass F1: 0.573\n",
      "Epoch 1000, Multiclass F1: 0.540\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Instantiate model once, with num_classes=2 for multiclass\n",
    "# model = SimpleCNN(input_channels=4, num_classes=2).to(device)\n",
    "model = InceptionCNN1D(input_channels=4, num_classes=2).to(device)\n",
    "\n",
    "# # Compute per-class weights from y_train (must be integer labels 0 or 1)\n",
    "# class_counts = np.bincount(y_train.astype(int), minlength=2)\n",
    "# class_weights = 1.0 / class_counts\n",
    "# class_weights = class_weights / class_weights.sum() * len(class_weights)  # optional normalization\n",
    "# weight_tensor = torch.tensor(class_weights, dtype=torch.float32, device=device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# --- Training loop ---\n",
    "for epoch in range(1000):\n",
    "    model.train()\n",
    "    for xb, yb in train_dl:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device).long()               # CrossEntropyLoss expects target shape (batch,) of dtype long\n",
    "        logits = model(xb)                      # shape: (batch, 2)\n",
    "        loss = criterion(logits, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # --- Validation epoch ---\n",
    "    model.eval()\n",
    "    val_preds, val_targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_dl:\n",
    "            xb = xb.to(device)\n",
    "            logits = model(xb)                  # shape: (batch, 2)\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            val_preds.extend(preds)\n",
    "            val_targets.extend(yb.numpy().astype(int))\n",
    "\n",
    "    f1 = f1_score(val_targets, val_preds, average='macro')\n",
    "    print(f\"Epoch {epoch+1}, Multiclass F1: {f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97     45016\n",
      "           1       0.06      0.80      0.11       240\n",
      "\n",
      "    accuracy                           0.93     45256\n",
      "   macro avg       0.53      0.87      0.54     45256\n",
      "weighted avg       0.99      0.93      0.96     45256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(val_targets, val_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiRocketMultivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.panel.rocket import MiniRocket\n",
    "\n",
    "# For example, 80% train, 20% test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y,\n",
    "    stratify=y,\n",
    "    test_size=0.20,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 3) Split train+val into train (60 %) and val (20 %)\n",
    "#    Since X_temp is 80 %, using test_size=0.25 on it gives 0.25*0.8 = 0.20 overall\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    stratify=y_temp,\n",
    "    test_size=0.25,\n",
    "    random_state=42\n",
    ")\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     segmented_df[['LAT','LON']], segmented_df[['Label']], test_size=0.2, random_state= 42, stratify=y  # stratify if classification\n",
    "# )\n",
    "\n",
    "# print(X_train.shape, X_test.shape)\n",
    "# print(y_train.shape, y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# clf = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "# clf.fit(X_train_tf, y_train)\n",
    "# y_pred = clf.predict(X_test_tf)\n",
    "# print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiRocket: Multiple pooling operators and transformations for fast and effective time series classification\n",
    "\n",
    "from sktime.transformations.panel.rocket import MultiRocketMultivariate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 1. Initialize and fit the MultiRocket transformer\n",
    "rocket = MultiRocketMultivariate(num_kernels=512)\n",
    "rocket.fit(X_train)\n",
    "\n",
    "# 2. Transform train and test sets\n",
    "X_train_rocket = rocket.transform(X_train)\n",
    "X_val_rocket = rocket.transform(X_val)\n",
    "X_test_rocket = rocket.transform(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Split into train+val (80 %) and test (20 %)\n",
    "X_handcrafted_temp, X_handcrafted_test, y_handcrafted_temp, y_handcrafted_test = train_test_split(\n",
    "    features_df, y,\n",
    "    stratify=y,\n",
    "    test_size=0.20,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 3) Split train+val into train (60 %) and val (20 %)\n",
    "#    Since X_temp is 80 %, using test_size=0.25 on it gives 0.25*0.8 = 0.20 overall\n",
    "X_handcrafted_train, X_handcrafted_val, y_handcrafted_train, y_handcrafted_val = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    stratify=y_temp,\n",
    "    test_size=0.25,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_handcrafted_train.shape, X_handcrafted_val.shape, X_handcrafted_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rocket.shape, X_val_rocket.shape, X_test_rocket.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Concatenate handcrafted and rocket features for each split\n",
    "X_train_combined = np.concatenate([X_handcrafted_train, X_train_rocket], axis=1)\n",
    "X_val_combined   = np.concatenate([X_handcrafted_val,   X_val_rocket],   axis=1)\n",
    "X_test_combined  = np.concatenate([X_handcrafted_test,  X_test_rocket],  axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', random_state=42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_curve, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# 1. Train RandomForest classifier\n",
    "clf = RandomForestClassifier(random_state=42, \n",
    "                             class_weight='balanced',\n",
    "                             n_estimators=100)\n",
    "clf.fit(X_train_rocket, y_train)\n",
    "# clf.fit(X_train_combined, y_train)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " test set @ threshold 0.1400:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     60022\n",
      "           1       0.68      0.49      0.57       320\n",
      "\n",
      "    accuracy                           1.00     60342\n",
      "   macro avg       0.84      0.75      0.78     60342\n",
      "weighted avg       1.00      1.00      1.00     60342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_probs = clf.predict_proba(X_val_rocket)[:, 1]\n",
    "# val_probs = clf.predict_proba(X_val_combined)[:, 1]\n",
    "\n",
    "# 3. Compute Precision-Recall curve on the validation set\n",
    "precision, recall, thresholds = precision_recall_curve(y_val, val_probs)\n",
    "\n",
    "# 4. Calculate F1 score for each threshold\n",
    "# (exclude last point because precision_recall_curve gives one extra point)\n",
    "epsilon = 1e-6  # to avoid division by zero\n",
    "f1_scores = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1] + epsilon)\n",
    "\n",
    "# 5. Select the threshold that gives the highest F1 score\n",
    "best_idx = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_idx]\n",
    "\n",
    "# 6. Apply the best threshold on the test set\n",
    "test_probs = clf.predict_proba(X_test_rocket)[:, 1]\n",
    "# test_probs = clf.predict_proba(X_test_combined)[:, 1]\n",
    "y_test_pred = (test_probs >= best_threshold).astype(int)\n",
    "\n",
    "# 7. Print classification report\n",
    "print(f\"\\n test set @ threshold {best_threshold:.4f}:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HIVE-COTE 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Split into train+val (80%) and test (20%)\n",
    "# Stratify ensures that the proportion of target variable 'y' is the same in all splits.\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y,\n",
    "    stratify=y,\n",
    "    test_size=0.20,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2) Split train+val into train (60%) and val (20%)\n",
    "# Since X_temp is 80%, using test_size=0.25 on it gives 0.25 * 0.8 = 0.20 overall\n",
    "X_train_orig, X_val, y_train_orig, y_val = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    stratify=y_temp,\n",
    "    test_size=0.25,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "print(\"\\nPreparing Undersampled Training Data...\")\n",
    "\n",
    "# Flatten the 3D array to 2D: (N, num_variables * seq_length)\n",
    "N, V, T = X_train_orig.shape\n",
    "X_train_flat = X_train_orig.reshape(N, V * T)\n",
    "\n",
    "# Apply undersampling\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_train_under_flat, y_train_under = undersampler.fit_resample(X_train_flat, y_train_orig)\n",
    "\n",
    "# Reshape back to 3D\n",
    "X_train_under = X_train_under_flat.reshape(-1, V, T)\n",
    "\n",
    "print(f\"Original training shape: {X_train_orig.shape}\")\n",
    "print(f\"Undersampled training shape: {X_train_under.shape}\")\n",
    "print(f\"Undersampled label distribution: {pd.Series(y_train_under).value_counts()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.hybrid import HIVECOTEV2\n",
    "\n",
    "clf = HIVECOTEV2(n_jobs = 10,\n",
    "                 time_limit_in_minutes=10,\n",
    "                 random_state=42,\n",
    "                 verbose= True,)\n",
    "\n",
    "clf.fit(X_train_under, y_train_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recfish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
